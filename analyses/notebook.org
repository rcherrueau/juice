#+COMMENT: -*- org-confirm-babel-evaluate: nil; -*-
#+TITLE: Evaluation of OpenStack Multi-Region Keystone Deployments
#+AUTHOR: Marie Delavergne, Ronan-Alexandre Cherrueau, Adrien Lebre
#+EMAIL: {firstname.lastname}@inria.fr
#+DATE: <2018-06-04 Mon>
#+LANGUAGE: en
#+OPTIONS: email:t ^:{} ':t broken-links:mark toc:nil H:4
#+MACRO: gh https://github.com/rcherrueau/juice/tree/master/$1
#+EXCLUDE_TAGS: noexport todo
#+LINK: juice-src https://github.com/BeyondTheClouds/juice/tree/master/%s
#+LINK: exp-src    https://enos.irisa.fr/juice/os-ocata/keystone-croach

#+COMMENT: HTML Properties
#+HTML_DOCTYPE: html5
#+OPTIONS: html5-fancy:t

#+COMMENT: Jekyll Properties
#+JEKYLL_LAYOUT: post
#+JEKYLL_CATEGORIES: OpenStack CockroachDB

#+COMMENT: Python Properties
#+PROPERTY: header-args:python :session notebook-eval
#+PROPERTY: header-args:python+ :eval no
#+COMMENT: #+PROPERTY: header-args:python+ :exports both  # export contains code + result see [[info:org#Exporting%20code%20blocks][info:org#Exporting code blocks]]

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="timeline.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.10.16/css/jquery.dataTables.css">
#+HTML_HEAD: <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha256-3edrmyuQ0w65f8gfBsqowzjJe2iM6n0nKciPUp8y+7E=" crossorigin="anonymous"></script>
# Tables
#+HTML_HEAD: <script type="text/javascript" charset="utf8" src="https://cdn.datatables.net/1.10.16/js/jquery.dataTables.js"></script>
# Images
#+HTML_HEAD: <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.css" />
#+HTML_HEAD: <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.js"></script>

#+BEGIN_abstract
OpenStack is the /de facto/ open source solution for the management of
cloud infrastructures and emerging solution for edge infrastructures
(/i.e./, hundreds of geo-distributed micro Data Centers composed of
dozens of servers interconnected through WAN links -- from 10 to 300
ms of RTT -- with intermittent connections and possible network
partitions). Unfortunately, some modules used by OpenStack services do
not fulfill edge infrastructure needs. For instance, core services use
the MariaDB Relational Database Management System (RDBMS) to store
their state. However, a single MariaDB may not cope with thousands of
connections and intermittent network access. Therefore, is OpenStack
technically ready for the management of an edge infrastructure? To
find this out, we built [[juice-src][Juice]]. Juice tests and
evaluates the performance of Relational Database Management Systems in
the context of a distributed OpenStack with high latency network. The
following study presents performance tests results together with an
analysis of these results for three RDBMS: (1) MariaDB, the OpenStack
default RDBMS; (2) Galera, the multi-master clustering solution for
MariaDB; (3) And CockroachDB, a NewSQL system that takes into account
the locality to reduce network latency effects.

Note: this post is currently in draft status. Experiment results lack
of explanation. It is going to be filled in the following days.
#+END_abstract

#+TOC: headlines 2

* Table of Contents                                      :TOC@2@org:noexport:
- [[Introduction][Introduction]]
- [[OpenStack at the Edge: the Keystone Use-Case][OpenStack at the Edge: the Keystone Use-Case]]
  - [[MariaDB and Keystone][MariaDB and Keystone]]
  - [[Galera in multi-master replication mode and Keystone][Galera in multi-master replication mode and Keystone]]
  - [[CockroachDB (/abbr./ CRDB) and Keystone][CockroachDB (/abbr./ CRDB) and Keystone]]
- [[Experiment Parameters][Experiment Parameters]]
  - [[A note about the Grid'5000 testbed and study conditions][A note about the Grid'5000 testbed and study conditions]]
  - [[Number of OpenStack instances][Number of OpenStack instances]]
  - [[Delay][Delay]]
- [[Load: Rally Scenarios][Load: Rally Scenarios]]
  - [[A typical Rally execution][A typical Rally execution]]
  - [[Low and high load][Low and high load]]
  - [[List of Rally scenarios][List of Rally scenarios]]
  - [[A note about gauging the %reads/%writes ratio][A note about gauging the %reads/%writes ratio]]
- [[Extract, Reify and Query Rally Experiments][Extract, Reify and Query Rally Experiments]]
  - [[From Json files to Python Objects][From Json files to Python Objects]]
  - [[Query Rally results][Query Rally results]]
- [[Experiment Analysis (skip to this section to see results)][Experiment Analysis (skip to this section to see results)]]
  - [[Number of OpenStack instances impact][Number of OpenStack instances impact]]
  - [[Delay impact][Delay impact]]
  - [[Taking into account the user locality][Taking into account the user locality]]
- [[Experiments Outline][Experiments Outline]]
- [[Appendix][Appendix]]
  - [[Detailed experiments results][Detailed experiments results]]
  - [[Detailed Rally scenarios][Detailed Rally scenarios]]
- [[Footnotes][Footnotes]]

* Prelude                                                          :noexport:
#+BEGIN_SRC python :results silent
# From standard lib
from typing import (Dict, Union, Iterator,
                    Callable, List, Tuple,
                    TypeVar, Generic) # Type annoation

T = TypeVar('T')
U = TypeVar('U')

from collections import OrderedDict
import copy
import glob                  # Unix style pathname
import itertools as itt
from operator import *
from functools import reduce
import re
import json
import textwrap

# Other libs
from dataclasses import dataclass   # Dataclass à la python 3.7
import objectpath                   # XPath for json
import pandas as pd                 # Data series analyses
import numpy as np
import matplotlib                   # Ploting
import matplotlib.pyplot as plt     # ^
from cycler import cycler           # ^
import seaborn as sns               # ^
import functional                   # For my sanity
from functional import seq          # ^
from functional.util import compose # ^

# -- Utils
linestyles = ('--','-.',':', '-')

def success_rate(rally_values) -> float:
    "Returns success rate of a Rally scenario"
    JPATH_STATUS  = '$.tasks[0].status'
    JPATH_SUCCESS = '$.tasks[0].subtasks[0].workloads[0].statistics.durations.total.data.success'
    success = 0
    # Rally status is either finished or crashed. In case of crashed,
    # the json contains no information about the scenarion execution.
    if rally_values.execute(JPATH_STATUS) == 'finished':
        # Rally success values is either:
        # - 'n/a' if the execution of the scenario failed
        # - A string that forms a percentage (e.g., '95.5%')
        success_str = rally_values.execute(JPATH_SUCCESS)
        if success_str.endswith('%'):
            success = round(float(success_str[:-1]) / 100., 2)
    #
    return success

def make_cumulative_frequency(s: pd.Series) -> pd.Series:
    "Performed a Cumulative Frequency Analysis"
    cum_dist = np.linspace(0.,1.,len(s))
    return pd.Series(cum_dist, index=s.sort_values())

def debug(t):
    "Debug in a λ"
    print(t)
    return t

def unpack(f):
    "Unpack tuple for pattern matching in lambda"
    def unpack_(args):
        if isinstance(args, functional.pipeline.Sequence):
            return f(*zip(*args))
        else:
            return f(*args)
    #
    return unpack_


def savefig(fig, filepath) -> 'filepath.svg':
    fig.savefig(filepath + '.svg')
    fig.savefig(filepath + '.pdf')
    fig.savefig(filepath + '.png')
    #
    return filepath + '.png'

def df2orgtable(df: pd.DataFrame, index_name="") -> List[List[str]]:
    """
    Formats a 2d pandas DataFrame into in a org table.

    The optional `index_name` let you label indices.
    """
    def _protect(l):
        return list(map(lambda s: '~' + s + '~' if '_' in s else s, map(str, l)))
    #
    columns = _protect(df.axes[1].values.tolist()) # columns names
    indices = _protect(df.axes[0].values.tolist()) # row labels
    rows    = df.values.tolist()         # rows
    # Put indeces in front of each row
    for index, r in enumerate(rows):
        r = list(map(lambda v: f'{v:.3f}', r))
        r.insert(0, indices[index])
        rows[index] = r
        #
    columns.insert(0, index_name)  # Id name in front of col names
    rows.insert(0, None)         # put a hline
    rows.insert(0, columns)      # put rows
    return rows

def df2orgtablestr(obj: Tuple['scenario', 'df_mean', 'df_std']) -> str:
    "Same as `df2orgtable` but produces a string"
    scn, df_mean, df_std = obj
    scn_short = textwrap.shorten((scn.replace('KeystoneBasic.', '')
                                  .replace('_', ' ')
                                  .title()),
                                 width=20,
                                 placeholder='...')
    df = df_mean.assign(std=df_std)
    res  = f'#+CAPTION: {scn}\n'
    res += f'#+NAME: tbl:{scn}\n'
    #
    for r in df2orgtable(df, scn_short):
        if r is None:
            res += "|--\n"
        else:
            res += "|" + reduce(add, intersperse_("|", map(str, r))) + "|\n"
            #
    return res

def xp2orgtable(xps: List['XP']) -> List[List[str]]:
    def xp2orgtablerow(xp) -> List[str]:
        "Format an `XP` into a org table row."
        delay = "LAN" if xp.delay == 0 else xp.delay * 2
        scn = xp.scenario.replace('KeystoneBasic.', '')
        rally_mode = "High" if xp.high else "Low"
        fp = f'[[file:{xp.filepath}][...{xp.filepath[-11:]}]]'
        return [xp.oss, delay, scn, rally_mode, xp.success, fp]
    # Make org table
    table = [ xp2orgtablerow(xp) for xp in xps ] # Body
    table.insert(0, None)                        # Hline
    table.insert(0, ["#Cluster", "RTT (ms)",     # Header
                     "Keystone Scenario",
                     "RMode", "Success", "Filepath"])
    return table

def _and(filters: List[Callable[[T], bool]]) -> Callable[[T], bool]:
    "Test a list of filter with AND"
    def __and(value: T) -> bool:
        for f in filters:
            if not f(value): return False
            #
        return True
    # Curry
    return __and

def _or(filters: List[Callable[[T], bool]]) -> Callable[[T], bool]:
    "Test a list of filter with OR"
    def __or(value: T) -> bool:
        for f in filters:
            if f(value): return True
            #
        return False
    # Curry
    return __or

def df_add_const_column(df: pd.DataFrame, cvalue: T, cname: str) -> pd.DataFrame:
    "Adds column `cname` with value `cvalue` to `df`."
    nb_dfrows = df.index.size
    new_column = {cname: [cvalue for i in range(nb_dfrows)]}
    return df.assign(**new_column)

# -- Monkey patch PyFunctional with new combinator
def truth_map_t(f: Callable[[T], Union[None, U]]):
    """Standart `map` that fileters non `operator.truth` values.

    Equivalent to `seq(x).map(f).filter(operator.truth)`

    >>> seq([1, 2, 3, -1, 0, 4]).truth_map(lambda x: str(x) if x > 0 else None)
    ['1', '2', '3', '4']
    """
    fname = functional.transformations.name(f)
    return functional.transformations.Transformation(
        f'truth_map({fname})',
        lambda sequence: seq(sequence).map(f).filter(truth),
        None)

def on_value_t(f: Callable[[T], U]):
    """Applies f on the second element of a (k, v).

    >>> seq([("k1", 1), ("k2", 2)]).on_value(str)
    [("k1", "1"), ("k2", "2")]
    """
    fname = functional.transformations.name(f)
    return functional.transformations.Transformation(
        f'on_key({fname})',
        # lambda sequence: map(lambda kv: (kv[0], f(kv[1])), sequence),
        lambda sequence: seq(sequence).map(lambda kv: (kv[0], f(kv[1]))),
        None)

def on_value_domap_t(f: Callable[[List[T]], List[U]]):
    """Maps f on the second element of a list of (k, [v]).

    >>> seq([("k1", [1, 1, 1]), ("k2", [2, 2, 2])]).on_value_domap(str)
    [("k1", ["1", "1", "1"]), ("k2", ["2", "2", "2"])]
    """
    fname = functional.transformations.name(f)
    return functional.transformations.Transformation(
        f'on_value_domap({fname})',
        # lambda sequence: map(lambda kv: (kv[0], seq(kv[1]).map(f)), sequence),
        lambda sequence: seq(sequence).map(lambda kv: (kv[0], seq(kv[1]).map(f))),
        None)

def push_t(e: T):
    """Add the element `e` in the sequence.

    >>> seq([1, 2]).push(0)
    [0, 1, 2]
    """
    def push(i: Iterator[any], e: any) -> Iterator[any]:
        l = list(i)
        l.insert(0, e)
        return l
    #
    ename = functional.transformations.name(e)
    return functional.transformations.Transformation(
        f'push({ename})',
        lambda sequence: push(sequence, e),
        None)

def intersperse_(delim: T, seq: Iterator[T]) -> Iterator[T]:
    it = iter(seq)
    yield next(it)
    for x in it:
        yield delim
        yield x

def intersperse_t(delim: T):
    ename = functional.transformations.name(delim)
    return functional.transformations.Transformation(
        f'intersperse({ename})',
        lambda sequence: intersperse(delim, sequence),
        None)

functional.pipeline.Sequence.truth_map = lambda self, f: self._transform(truth_map_t(f))
functional.pipeline.Sequence.on_value = lambda self, f: self._transform(on_value_t(f))
functional.pipeline.Sequence.on_value_domap = lambda self, f: self._transform(on_value_domap_t(f))
functional.pipeline.Sequence.push = lambda self, e: self._transform(push_t(e))
functional.pipeline.Sequence.intersperse = lambda self, e: self._transform(intersperse_t(e))
functional.pipeline.Sequence.__len__ = lambda self: self.len()
functional.pipeline.Sequence.head = lambda self: self.take(1).to_list().pop()

# plot config
sns.set()
sns.set_context("notebook")
sns.set_style("darkgrid", {"legend.frameon": True})
# sns.set_palette(sns.color_palette("Set2", 9))
sns.set_palette(sns.color_palette('deep', 9))
#+END_SRC

* Introduction
Internet of things, virtual reality or network function virtualization
use-cases all require edge infrastructures. An edge infrastructure
/could/ be defined as up to hundreds individually-managed and
geo-distributed micro data centers composed of up to dozens of
servers. The expected latency and bandwidth between elements may
fluctuate, in particular because networks can be wired or wireless.
And disconnections between sites may also occur, leading to network
partitioning situations. This kind of edge infrastructure shares
common basis with cloud computing, notably in terms of management.
Therefore developers and operators (DevOps) of an edge infrastructure
expect to find most features that made current cloud solutions
successful. Unfortunately, there is currently no resource management
system able to deliver all these features for the egde.

Building an edge infrastructure resource management system from
scratch seems unreasonable. Hence the Discovery initiative has been
investigating how to deliver such a system leveraging OpenStack, the
cloud computing infrastructure resource manager. From a bird's-eye
view, OpenStack has two type of nodes: data nodes delivering XaaS
capabilities (compute, storage, network, ..., i.e., data plane) and
control nodes executing OpenStack services (i.e., control plane).
Whenever a user issues a request to OpenStack, the control plane
processes the request which may potentially also affect the data plane
in some manner.

Preliminary studies we conducted enabled us to identify diverse
OpenStack deployment scenarios for the edge: from a fully centralized
control plane to a fully distributed control plane. These deployment
scenarios have been elaborated in the [[https://hal.archives-ouvertes.fr/view/index/docid/1812747][Edge Computing Resource
Management System: a Critical Building Block!]] research paper that will
be presented at the USENIX HotEdge'18 Workshop (July 2018).

This post presents the study we conducted regarding the Keystone
Identity Service responsible for authentication and authorization in
OpenStack. By varying the number of OpenStack instances and latency
between instances, we compare the following deployments:
- One centralized MariaDB handling requests of every Keystone in
  OpenStack instances.
- A replicated Keystone using Galera Cluster to synchronize databases
  in the different OpenStack instances.
- A global Keystone using the global geo-distributed CockroachDB
  database.

Note that some results of this study [[https://www.openstack.org/videos/vancouver-2018/keystone-in-the-context-of-fogedge-massively-distributed-clouds][have been presented]] during the
2018 Vancouver OpenStack Summit. This post contains additional
information, though. Notably, this post is based on [[https://orgmode.org/][org mode]] with
[[https://orgmode.org/worg/org-contrib/babel/][babel]], thus executing it [[juice-src:analyses/notebook.org][from source]] computes the following post
including plots for the results.

* OpenStack at the Edge: the Keystone Use-Case
OpenStack comes with several deployment alternatives for the
edge[fn:os-deplyment-alternatives]. A [[https://www.openstack.org/videos/boston-2017/toward-fog-edge-and-nfv-deployments-evaluating-openstack-wanwide][naive]] one consists in a
centralized control plane. In this deployment, OpenStack operates an
edge infrastructure as a traditional single data center environment,
except that there is a wide-area network between the control and
compute nodes. A second alternative consists in distributing OpenStack
services by distributing their database and message bus. In this
deployment, all OpenStack instances share the same state thanks to the
distributed database. They also implement intra-service collaboration
thanks to the distributed message bus.

Deploying a multi-region Keystone is [[https://www.openstack.org/videos/vancouver-2018/highly-resilient-multi-region-keystone-deployments][a concrete example]] of these
deployment alternatives. To scale, current OpenStack deployments put
instances of OpenStack in different regions around the globe. But,
operators want to have all of their users and projects available
across all regions. That means, a sort of global Keystone available
from every region. To this aim, an operator got two options. First,
she can centralize Keystone (or its [[https://mariadb.org/][MariaDB]] database) in one region
and make other regions refer to the first one. Second, she can use
[[http://galeracluster.com/][Galera Cluster]] to synchronize Keystones' database and thus distribute
the service.

This study targets the /performance evaluation/ of a multi-region
Keystone with the MariaDB and Galera deployment alternatives plus a
variant of the Galera alternative based on [[https://www.cockroachlabs.com/][CockroachDB]]. CockroachDB is
a NewSQL database that claims to scale while implementing ACID
transactions. Especially, CockroachDB makes it possible to take into
account the locality of Keystone users to reduce latency effects. The
following section presents each database, their relative Keystone
deployments and expected limitations.

#+CAPTION: List of Evaluated RDBMS.
#+NAME: lst:rdbms
#+BEGIN_SRC python :results silent
RDBMSS = [ 'mariadb', 'galera', 'cockroachdb' ]
#+END_SRC

** MariaDB and Keystone
MariaDB is a fork of MySQL, intended to stay free and under GNU
General Public License. It maintains high compatibility with MySQL,
keeping the same APIs and commands.

**** Multiple OpenStack instances deployment with a single MariaDB
Figure [[fig:mariadb]] depicts the deployment of MariaDB. MariaDB is a
centralized RDBMS and thus, the Keystone backend is centralized in the
first OpenStack instance. Other Keystones of other OpenStack instances
refers to the backend of the first instance.

This kind of deployment comes with two possible limitations. First, a
centralized RDBMS is a SPoF that makes all OpenStack instances
unusable if it crashes. Second, a network disconnection of the,
/e.g./, third OpenStack instance with the first one makes the third
unusable.

#+CAPTION: Keystone Deployment with a Centralized MariaDB.
#+NAME: fig:mariadb
[[file:imgs/mariadb.png]]

** Galera in multi-master replication mode and Keystone
MariaDB uses Galera Cluster as a synchronous multi-master cluster. It
means that all nodes in the cluster are masters, with active-active
synchronous replication, so it is possible to read or write on every
node at any time. To put it simply, MariaDB Galera Cluster allows
having the same database on every node thanks to synchronous
replication.

To dive more into details, each time a client performs a transaction
request on a node, it is processed as usual until the client issues a
commit. The process is stopped and all changes made to the database in
the transaction are collected in a "write-set", along with the primary
keys of the changed rows. The write-set is then broadcasted to every
node with a global identifier[fn:global-id] to order it regarding
other write-sets. The write-set finally undergoes a deterministic
certification test which uses the given primary keys. It checks all
transactions between the current transaction and the last successful
one to determine whether the primary keys involved conflicts between
each other. If the check fails, Galera rollbacks the whole
transaction, and if it succeeds, Galera applies and commit the
transaction on all nodes.

#+CAPTION: Certification Based Replication from [[http://galeracluster.com]].
#+NAME: fig:galera
[[file:imgs/commit-galera.gif]]

This is pretty efficient since it only needs one broadcast to make the
replication, which means the commit does not have to wait for the
responses of the other nodes. But, this means that when it fails, the
entire transaction must be retried and so it may lead to more
conflicts and even deadlocks.

**** Multiple OpenStack instances deployment with Galera
Figure [[fig:galera-deployment]] depicts the deployment of Galera. Galera
synchronizes multiple MariaDB in an active/active fashion. Thus
Keystone's backend of every OpenStack instance is replicated between
all nodes, which allows reads and writes on any instances.

Regarding possible limitations, few rumors stick to Galera. First,
synchronization may suffer from high latency networks. Second,
contention during writes on the database may limit its scalability.

#+CAPTION: Keystone Deployment with Synchronization using Galera.
#+NAME: fig:galera-deployment
[[file:imgs/galera.png]]

** CockroachDB (/abbr./ CRDB) and Keystone
CockroachDB is a NewSQL database that uses the Raft protocol (an
alternative version to Lamport's Paxos consensus protocol). It uses
the SQL API to enable SQL requests on every node. These requests are
translated to key-value operations and -if needed- distributed across
the cluster.

CockroachDB implements a single, monolithic sorted map for the keys
and values stored, as seen in [[fig:cockroachdb]]. This map is divided in
ranges, which are continuous chunks of this map, with every key being
in a single range, so the ranges will not overlap. Each range is then
replicated (default to three replicas per range) and finally
distributed across the cluster nodes.

#+CAPTION: CockroachDB Ranges, Replicas
#+CAPTION: and Leaseholders (blue points).
#+NAME: fig:cockroachdb
[[file:imgs/cockroachdb.png]]

One of the replicas acts as the leaseholder, a sort of leader that
coordinates all reads and writes for the range. A read only requires
the leaseholder. When a write is requested, the leaseholder prepares
to append it to its log, forward the request to the replicas and when
the quorum is achieved, commit the change by adding it in the log. The
quorum is an agreement from two out of the three replicas to make the
change.

#+CAPTION: CockroachDB commit
#+NAME: fig:galera
[[file:imgs/commit-cockroachdb.gif]]

#+BEGIN_COMMENT
To implement an SQL API, Cockroach uses an encoding tool to go from
SQL data to a key-value store. As an example, a bit of code:
#+BEGIN_SRC sql :eval no
CREATE TABLE test (
      key       INT PRIMARY KEY,
      floatVal  FLOAT,
      stringVal STRING
)

INSERT INTO test VALUES (10, 4.5, "hello")
#+END_SRC

This row would be stored as:

|--------------------+---------|
| Key                | Value   |
|--------------------+---------|
| /test/10/floatVal  | 4.5     |
| /test/10/stringVal | "hello" |
|--------------------+---------|

Here, ~/test/~ is a placeholder for the table ID and the ~/*Val~ are
placeholders for the column ID used in CockroachDB. Each non-primary
key column are stored under a separate key that is prefixed by the
primary key (following the table ID) and suffixed by the column ID.
#+END_COMMENT

**** Multiple OpenStack instances deployment with CockroachDB
Figure [[fig:crdb]] depicts the deployment of CockroachDB. In this
deployment, each OpenStack instance has its Keystone. The backend is
distributed through key-value stores on every OpenStack instance.
Meaning, the data a Keystone is sought for is not necessarily in its
local key-value store.

CockroachDB is relatively new and we know a few about its limitations,
but first, CockroachDB may suffer from high network latency even
during reads if the current node that gets the requests is not the
leaseholder. Second, as Galera, transaction contention may
dramatically slow down the overall execution. However, CockroachDB
offers locality option to drive the selection of key-value stores
during writes and replication. Thanks to this option it would be
possible to mitigate the impact of latency by ensuring that writes
happen close to the OpenStack operator.

#+CAPTION: Keystone Deployment with Distributed
#+CAPTION: Backend using CockroachDB.
#+NAME: fig:crdb
[[file:imgs/crdb.png]]

* Experiment Parameters
This section outline the two parameters considered in this study:
first, the number of OpenStack instances and second, network latency.
Later, the section on the locality (see, [[*Taking into account the user locality][Taking into account the user locality]]) adds a third
parameter to study heterogeneous network infrastructures.

** A note about the Grid'5000 testbed and study conditions
[[https://docs.openstack.org/developer/performance-docs/labs/grid5000.html][Grid'5000]] is a large-scale and versatile testbed for experiment-driven
research in all areas of computer science, with a focus on parallel
and distributed computing including Cloud, HPC and Big Data. The
platform gives access to approximately 1000 machines grouped in 30
clusters geographically distributed in 8 sites. This study uses the
[[https://www.grid5000.fr/mediawiki/index.php/Nantes:Hardware#ecotype][ecotype cluster]] made of 48 nodes with each:
- CPU :: Intel Xeon E5-2630L v4 Broadwell 1.80GHz (2 CPUs/node, 10
         cores/CPU)
- Memory :: 128 GB
- Network ::
  - eth0/eno1, Ethernet, configured rate: 10 Gbps, model: Intel
    82599ES 10-Gigabit SFI/SFP+ Network Connection, driver: ixgbe
  - eth1/eno2, Ethernet, configured rate: 10 Gbps, model: Intel
    82599ES 10-Gigabit SFI/SFP+ Network Connection, driver: ixgbe

The deployment of OpenStack relies on [[https://github.com/openstack-dev/devstack/tree/stable/pike][devstack stable/pike]] and uses
default parameter for Keystone (/e.g.,/ SQL backend, fernet token,
...). Juice deploys a docker version of RDBMS and tweaks a little bit
devstack to ensure Keystone connects to the right RDBMS container.
Note that devstack (and OpenStack) does not support CockroachDB. We
[[https://beyondtheclouds.github.io/blog/openstack/cockroachdb/2017/12/22/a-poc-of-openstack-keystone-over-cockroachdb.html][published a post a few months ago]] about the support of CockroachDB in
Keystone. Note also that RDBMS are stored directly on the memory.

** Number of OpenStack instances
The OpenStack size (see, lst. [[lst:oss]]) defines the number of OpenStack
instances deployed for an experiment. It varies between ~3~, ~9~ and
~45~. A value of ~3~, means Juice deploys OpenStack on three different
nodes, ~9~ on nine different nodes, ... The value of ~45~ comes from
the maximum number of nodes available on the ecotype Grid'5000
cluster, but Juice is not limited to.

#+CAPTION: List of Number of OpenStack Instances Deployed.
#+NAME: lst:oss
#+BEGIN_SRC python :results silent
OSS = [ 3, 9, 45 ]
#+END_SRC

Experiments that test the impact of the number of OpenStack instances
(see, [[*Number of OpenStack instances impact][Number of OpenStack instances impact]]) consider a LAN link
between each OpenStack instances.

** Delay
The delay (see, lst. [[lst:delays]]) defines the network latency between
two OpenStack instances. It is expressed in terms of half the
Round-Trip Times, (/i.e./, a value of ~50~ stands for 100 ms of RTT,
~150~ is 300 ms of RTT). The ~0~ value stands for LAN speed which is
approximately 0.08 ms of RTT on the ecotype Grid'5000 cluster (10 Gbps
card).

#+CAPTION: List of Network Latency Between Two OpenStack Instances.
#+NAME: lst:delays
#+BEGIN_SRC python :results silent
DELAYS = [ 0, 50, 150 ]
#+END_SRC

Juice applies theses network latencies with ~tc~ [[https://wiki.linuxfoundation.org/networking/netem][netem]]. Note that
juice applies ~tc~ rules on network interfaces dedicated to the RDBMS
communications. Thus, metrics collection and other network
communication are not limited.

Experiments that test the impact of the network latency (see, [[*Delay impact][Delay
impact]]) are done with 9 OpenStack instances. They make the delay
varies by applying traffic shaping homogeneously between the 9
OpenStack instances.

* Load: Rally Scenarios
Juice uses [[https://rally.readthedocs.io/en/latest/][Rally]], a testing benchmarking tool for OpenStack, to
evaluate how OpenStack control plane behaves at scale. This section
describes Rally scenarios considered in this study. The description
includes the ratio of reads and writes performed on the database. For
a transactional (OLTP) database, depending on the reads/writes ratio,
it could be better to choose one replication strategy to another
(i.e., replicate records on all of your nodes or not).

** A typical Rally execution
A Rally executes its load on one instance of OpenStack. Two variables
configure the execution of a Rally scenario: the /times/ which is the
number of iteration execution performed for a scenario, and
/concurrency/ which is the number of parallel iteration execution.
Thus, a scenario with times of ~100~ runs one hundred iterations of
the scenario by a constant load on the OpenStack instance. A
concurrency of ~10~ specifies that ten users concurrently achieve the
one hundred iterations. The execution output of such a scenario may
look like this:
#+BEGIN_EXAMPLE
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 1 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 2 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 4 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 3 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 5 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 6 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 8 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 7 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 9 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 10 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 4 END
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 11 START
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 3 END
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 12 START
...
Task 19b09a0b-7aec-4353-b215-8d5b23706cd7 | ITER: 100 END
#+END_EXAMPLE

#+BEGIN_COMMENT
This behavior corresponds to the constant runner. Rally lets you
change the runner for a serial one which is equivalent to a
concurrency of ~1~.
#+END_COMMENT

** Low and high load
The juice tool runs two kinds of load: /low/ and /high/. The low load
starts one Rally instance on only one OpenStack instance. The high
load starts as many Rally instances as OpenStack instances.

The high load is named as such because it generates a lot of requests
and thus, a lot of contention on distributed RDBMS. The case of ~45~
Rally instances with a concurrency of ~10~ and times of ~100~ charges
~450~ constant transactions on the RDBMS up until getting to ~4,500~
iteration.

** List of Rally scenarios
Here is the complete list of rally scenarios considered in this study.
Values inside the parentheses refer to the percent of reads versus the
percent of writes on the RDBMS. More information about each scenario
is available in the appendix (see, [[*Detailed Rally scenarios][Detailed Rally scenarios]]).

- keystone/authenticate-user-and-validate-token (96.46, 3.54) :: Authenticate
     and validate a Keystone token.
- keystone/create-add-and-list-user-roles (96.22, 3.78) :: Create a
     user role, add it and list user roles for given user.
- keystone/create-and-list-tenants (92.12, 7.88) :: Create a Keystone
     tenant with random name and list all tenants.
- keystone/get-entities (91.9, 8.1) :: Get instance of a tenant, user,
     role and service by id's. An ephemeral tenant, user, and role are
     each created. By default, fetches the 'keystone' service.
- keystone/create-user-update-password (89.79, 10.21) :: Create a
     Keystone user and update her password.
- keystone/create-user-set-enabled-and-delete (91.07, 8.93) :: Create
     a Keystone user, enable or disable it, and delete it.
- keystone/create-and-list-users (92.05, 7.95) :: Create a Keystone
     user with random name and list all users.

** A note about gauging the %reads/%writes ratio
The %reads/%writes ratio is computed on MariaDB. The gauging code
reads values of status variables ~Com_xxx~ that provide statement
counts over all connections (with ~xxx~ stands for ~SELECT~, ~DELETE~,
~INSERT~, ~UPDATE~, ~REPLACE~ statements). The SQL query that does
this job is available in listing [[lst:gauging-ratio-sql]] and returns the
total number of reads and writes since the database started. Juice
executes that SQL query before and after the execution of one Rally
scenario. After and before values are then subtracted to compute the
number of reads and writes performed during the scenario and finally,
compared to compute the ratio.

#+CAPTION: Total number of reads and writes performed on
#+CAPTION: MariaDB since the last reboot
#+NAME: lst:gauging-ratio-sql
#+BEGIN_SRC sql :eval no
SELECT
  SUM(IF(variable_name = 'Com_select', variable_value, 0))
     AS `Total reads`,
  SUM(IF(variable_name IN ('Com_delete',
                           'Com_insert',
                           'Com_update',
                           'Com_replace'), variable_value, 0))
     AS `Total writes`
FROM  information_schema.GLOBAL_STATUS;
#+END_SRC

Note that %reads/%writes may be a little bit more in favor of reads
than what it is presented here because the following also takes into
account the creation/deletion of the Rally context. A basic Rally
context for a Keystone scenario is ~{"admin_cleanup@openstack":
["keystone"]}~. Not sure what does this context do exactly though,
maybe it only creates an admin user...

#+BEGIN_COMMENT
This context may be extended by other inserts specified in the
scenario definition (under the ~context~ key; see scenario definition
for [[*keystone/create-add-and-list-user-roles][keystone/create-add-and-list-user-roles]]).
#+END_COMMENT

The Juice implementation for this gauging is available on GitHub at
[[https://github.com/rcherrueau/juice/blob/02af922a7c3221462d7106dfb2751b3be709a4d5/experiments/read-write-ratio.py][experiments/read-write-ratio.py]].

** Python params                                                   :noexport:
#+BEGIN_SRC python :results silent
RALLY = OrderedDict([
  ("KeystoneBasic.authenticate_user_and_validate_token", {
    "operations": ["keystone_v3.fetch_token", "keystone_v3.validate_token",],
    "iterations": 20,
    "reads": 13339,
    "writes": 489,
    "%reads": 96.46,
    "%writes": 3.54
  }),
  ("KeystoneBasic.create_add_and_list_user_roles", {
    "operations": ["keystone_v3.create_role", "keystone_v3.add_role",
                   "keystone_v3.list_roles",],
    "iterations": 100,
    "reads": 13303,
    "writes": 523,
    "%reads": 96.22,
    "%writes": 3.78
  }),
  ("KeystoneBasic.create_and_list_tenants", {
    "operations": ["keystone_v3.create_project", "keystone_v3.list_projects",],
    "iterations": 10,
    "reads": 1427,
    "writes": 122,
    "%reads": 92.12,
    "%writes": 7.88
  }),
  ("KeystoneBasic.get_entities", {
   "operations": ["keystone_v3.create_project",
                  "keystone_v3.create_user", "keystone_v3.create_role",
                  "keystone_v3.get_project", "keystone_v3.get_user",
                  "keystone_v3.get_role", "keystone_v3.list_services",
                  "keystone_v3.get_services",],
    "iterations": 100,
    "reads": 25427,
    "writes": 2242,
    "%reads": 91.9,
    "%writes": 8.1
  }),
  ("KeystoneBasic.create_user_update_password", {
    "operations": ["keystone_v3.create_user", "keystone_v3.update_user",],
    "iterations": 100,
    "reads": 13554,
    "writes": 1542,
    "%reads": 89.79,
    "%writes": 10.21
  }),
  ("KeystoneBasic.create_user_set_enabled_and_delete", {
    "operations": ["keystone_v3.create_user", "keystone_v3.update_user",
                   "keystone_v3.delete_user",],
    "iterations": 100,
    "reads": 25125,
    "writes": 2463,
    "%reads": 91.07,
    "%writes": 8.93
  }),
  ("KeystoneBasic.create_and_list_users", {
    "operations": ["keystone_v3.create_user", "keystone_v3.list_users",],
    "iterations": 100,
    "reads": 12061,
    "writes": 1042,
    "%reads": 92.05,
    "%writes": 7.95
  })])
#+END_SRC

* Experiments raw results                                          :noexport:
All test are run in light (l) and high (h) mode.

#+NAME: tbl:mariadb-experiments
|     |    3 | 9    |   45 |
|-----+------+------+------|
|   0 | [[file:ecotype-exp-backoff/mariadb-3-0-F][l]], [[file:ecotype-exp-backoff/mariadb-3-0-T][h]] | [[file:ecotype-exp-backoff/mariadb-9-0-F][l]], [[file:ecotype-exp-backoff/mariadb-9-0-T][h]] | [[file:ecotype-exp-backoff/mariadb-45-0-F][l]], [[file:ecotype-exp-backoff/mariadb-45-0-T][h]] |
|  50 |      | [[file:ecotype-exp-backoff/mariadb-9-50-F][l]], [[file:ecotype-exp-backoff/mariadb-9-50-T][h]] |      |
| 150 |      | [[file:ecotype-exp-backoff/mariadb-9-150-F][l]], [[file:ecotype-exp-backoff/mariadb-9-150-T][h]] |      |

#+NAME: tbl:galera-experiments
|     |    3 | 9    |   45 |
|-----+------+------+------|
|   0 | [[file:ecotype-exp-backoff/galera-3-0-F][l]], [[file:ecotype-exp-backoff/galera-3-0-T][h]] | [[file:ecotype-exp-backoff/galera-9-0-F][l]], [[file:ecotype-exp-backoff/galera-9-0-F][h]] | [[file:ecotype-exp-backoff/galera-45-0-F][l]], [[file:ecotype-exp-backoff/galera-45-0-T][h]] |
|  50 |      | [[file:ecotype-exp-backoff/galera-9-50-F][l]], [[file:ecotype-exp-backoff/galera-9-50-T][h]] |      |
| 150 |      | [[file:ecotype-exp-backoff/galera-9-150-F][l]], [[file:ecotype-exp-backoff/galera-9-150-T][h]] |      |

#+NAME: tbl:cockroachdb-experiments
|     |    3 | 9    |   45 |
|-----+------+------+------|
|   0 | [[file:ecotype-exp-backoff/cockroachdb-3-0-F][l]], [[file:ecotype-exp-backoff/cockroachdb-3-0-T][h]] | [[file:ecotype-exp-backoff/cockroachdb-9-0-F][l]], [[file:ecotype-exp-backoff/cockroachdb-9-0-T][h]] | [[file:ecotype-exp-backoff/cockroachdb-45-0-F][l]], [[file:ecotype-exp-backoff/cockroachdb-45-0-T][h]] |
|  50 |      | [[file:ecotype-exp-backoff/cockroachdb-9-50-F][l]], [[file:ecotype-exp-backoff/cockroachdb-9-50-T/env][h]] |      |
| 150 |      | [[file:ecotype-exp-backoff/cockroachdb-9-150-F][l]], [[file:ecotype-exp-backoff/cockroachdb-9-150-T][h]] |      |

* Extract, Reify and Query Rally Experiments
The execution of a Rally scenario (such as those seen in the previous
section -- see [[*Load: Rally Scenarios][Load: Rally Scenarios]]) produces a JSON file. The JSON
file contains a list of entries: one for each iteration of the
scenario. An entry then retains the time (in seconds) it takes to
complete all Keystone operations involved in the Rally scenario.

This section provides python facilities to extract and query Rally
results for later analyses. Someone interested by the results and not
by the process to compute them may skip this section and jump to the
next one (see, [[*Number of OpenStack instances impact][Number of OpenStack instances impact]]).

#+BEGIN_COMMENT
This study evaluate different database backends in the context of
an OpenStack for the edge on the basis of Rally benchmarking tool.

: for i in $(ls -d */); do pushd $i; ls backup/*/rally*.tar.gz | xargs -I '{}' tar -xf '{}'; popd; done
: for i in $(ls -d */); do cd $i; echo $i; ls -l rally_home/*.json|wc -l; cd ..; done  # 7/21/7/315/7/63/7/63/7/63
#+END_COMMENT

An archive with results of all experiments in this study is available
at [[exp-url]]. It contains general metrics collected over the experiments
time such as the CPU/RAM consumption, network communications (all
stored in a influxdb), plus Rally JSON result files. Let's assume the
~XPS_PATH~ variable references the path to the extracted archive.
Listing [[lst:xp-paths]] defines accessors for all Rally JSON result files
thanks to the [[https://docs.python.org/3/library/glob.html][~glob~]] python module. The ~glob~ module finds all paths
that match specified UNIX patterns.

#+CAPTION: Paths to Rally JSON Results File.
#+NAME: lst:xp-paths
#+BEGIN_SRC python :results silent
XP_PATHS = './ecotype-exp-backoff/'
MARIADB_XP_PATHS = glob.glob(XP_PATHS + 'mariadb-*/rally_home/*.json')
GALERA_XP_PATHS = glob.glob(XP_PATHS + 'galera-*/rally_home/*.json')
CRDB_XP_PATHS = glob.glob(XP_PATHS + 'cockroachdb-*/rally_home/*.json')
#+END_SRC

** From Json files to Python Objects
A data class ~XP~ retains data of one experiment (i.e., the name of
the Rally scenario, name of database technology, ... -- see l.
[[(xp-dataclass-start)]] to [[(xp-dataclass-end)]] of listing [[lst:xp-dataclass]]
for the complete list). Reefing experiment data in a Python object
helps for the later analyses. Indeed, a Python object makes it easier
to filter, sort, map, ... experiments.

#+CAPTION: Experiment Data Class.
#+NAME: lst:xp-dataclass
#+BEGIN_SRC python -n -r :results silent :noweb strip-export
@dataclass(frozen=True)
class XP:
    scenario: str             # Rally scenario name (ref:xp-dataclass-start)
    rdbms: str                # Name of the RDBMS (e,g, cockcroachdb, galera)
    filepath: str             # Filepath of the JSON file
    oss: int                  # Number of OpenStack instances
    delay: int                # Delay between nodes
    high: bool                # Experiment performed during a high or light load
    success: float            # Success rate (e.g., 1.0)
    dataframe: pd.DataFrame   # Results in a pandas 2d DataFrame (ref:xp-dataclass-end)
    <<lst:xp_zones>>
    <<lst:xp_immutable_set>>
#+END_SRC

The ~XP~ data class comes with the ~make_xp~ function (see, lst.
[[lst:make_xp]]). It produces an ~XP~ object from an experiment file path
(i.e., Rally JSON file). Especially, it uses the python [[http://objectpath.org/][~objectpath~]]
module that provides a DSL to query JSON documents (à la XPath) and
extract only interesting data.

#+CAPTION: Builds an ~XP~ object from a Rally JSON Result File.
#+NAME: lst:make_xp
#+BEGIN_SRC python -r -n :results silent :noweb strip-export
def make_xp(rally_path: str) -> XP:
    # Find XP name in the `rally_path`
    RE_XP = r'(?:mariadb|galera|cockroachdb)-[a-zA-Z0-9\-]+'
    # Find XP params in the `rally_path` (e.g., rdbms, number of OS instances, delay, ...)
    RE_XP_PARAMS = r'(?P<db>[a-z]+)-(?P<oss>[0-9]+)-(?P<delay>[0-9]+)-(?P<zones>[Z0-9]{6})-(?P<high>[TF]).*'
    # JSON path to the rally scenario's name
    JPATH_SCN = '$.tasks[0].subtasks[0].title'
    <<lst:dataframe_per_operations>>
    with open(rally_path) as rally_json:
        rally_values = objectpath.Tree(json.load(rally_json))
        xp_info = re.match(RE_XP_PARAMS, re.findall(RE_XP, rally_path)[0]).groupdict()
        success = success_rate(rally_values)
        return XP(
            scenario = rally_values.execute(JPATH_SCN),
            filepath = rally_path,
            rdbms = xp_info.get('db'),
            oss = int(xp_info.get('oss')),
            delay = int(xp_info.get('delay')),
            success = success, <<lst:make_xp_zones>>
            high = True if xp_info.get('high') is 'T' else False,
            dataframe = dataframe_per_operations(rally_values)) if success else None (ref:dataframe_per_operations)
#+END_SRC

The [[(dataframe_per_operations)][~dataframe_per_operations~]] (see l. [[(dataframe_per_operations)]]) is a function
that transforms Rally JSON results in a pandas [[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame][~DataFrame~]] for result analyses.
The next section will says more on this. Right now, focus on ~make_xp~. With
~make_xp~, transforming all Rally JSONs into ~XP~ objects is as simple as
mapping over experiment paths (see lst. [[lst:xps]]).

#+CAPTION: From Json Files to Python Objects.
#+NAME: lst:xps
#+BEGIN_SRC python :results silent
XPS = seq(MARIADB_XP_PATHS + GALERA_XP_PATHS + CRDB_XP_PATHS).truth_map(make_xp)
#+END_SRC

This study also comes with a bunch of predicates in its toolbelt that
ease the filtering and sorting of experiments. For instance, a
function src_python[:exports code :eval no]{def is_crdb(xp: XP) ->
bool} only keeps CockroachDB experiments. Likewise,
src_python[:exports code :eval no]{def xp_csize_rtt_b_scn_order(xp:
XP) -> str} returns a comparable value to sort experiments. The
complete list of predicates is available in the source of this study.

*** Extra Code                                                     :noexport:
Implement an immutable set interface for ~XP~.
#+NAME: lst:xp_immutable_set
#+BEGIN_SRC python :results silent
# Immutable setter
def set_dataframe(self: 'XP', df: pd.DataFrame) -> 'XP':
    return XP(scenario=self.scenario,
              filepath=self.filepath,
              rdbms=self.rdbms,
              oss=self.oss,
              delay=self.delay,
              zones=self.zones,
              high=self.high,
              success=self.success,
              dataframe=df)
#+END_SRC

Normalize experiments, i.e., make NaN dataframe for results that crashed.
#+BEGIN_SRC python :results silent :noweb no-export :exports none
<<lst:predicate>>
<<lst:hlq>>
<<lst:hlp>>

# Normalize experiments (ie, make NaN dataframe for resutls that crashed)
RESULTS = XPS.group_by(lambda xp: (xp.rdbms, xp.scenario, xp.oss, xp.high, xp.delay, xp.zones)).to_dict()
normalized_xps = []
for (rdbms, scn, high, (oss, delay, zones)) in [ (r, s, h, c)
                                          for r in RDBMSS
                                          for s in RALLY.keys()
                                          for h in [False, True]
                                          # We have resutls for these combinations of OS Instances/Delay:
                                          for c in [ (3, 0, ('Z1','Z1','Z1')), (9, 0, ('Z1','Z1','Z1')), (45, 0, ('Z1','Z1','Z1')),
                                                     (9, 50, ('Z1','Z1','Z1')), (9, 150, ('Z1','Z1','Z1')),
                                                     (9, 10, ('Z1','Z2','Z3')), (9, 10, ('Z1','Z1','Z3')), (9, 10, ('Z1','Z1','Z1')) ] ]:
    # Get the list of XP
    xps = RESULTS.get((rdbms, scn, oss, high, delay, zones), [])
    if not high and len(xps) == 0:
        normalized_xps += make_xps(scn, rdbms, oss, delay, high, zones, 1)
    #
    elif high and len(xps) < oss:
        normalized_xps += xps + make_xps(scn, rdbms, oss, delay, high, zones, oss - len(xps))
    #
    else:
        normalized_xps += xps

# Memoization
NORMALIZED_XPS = seq(normalized_xps).order_by(xp_csize_rtt_b_scn_order).cache()
Z1_XPS = NORMALIZED_XPS.filter(when_zones(('Z1', 'Z1', 'Z1'))).cache()
XPS = Z1_XPS
#+END_SRC

*** MariaDB experiments                                            :noexport:
Listing [[lst:mariadb_xps]] shows how to compute the list of experiments
for MariaDB (~filter(is_crdb)~). Table [[tab:crdb_xps]] presents the
results.

#+CAPTION: Access to MariaDB Experiments.
#+NAME: lst:mariadb_xps
#+BEGIN_SRC python :results silent
MARIADB_XPS = XPS.filter(is_mariadb)
#+END_SRC

#+BEGIN_COMMENT
The ~xp2orgtable~ is a [[*Prelude][Prelude]] function that takes a list of ~XP~ and
formats them into an Org table as table [[tab:crdb_xps]].
#+END_COMMENT

#+HEADER: :colnames yes :hlines yes
#+NAME: lst:mariadb_xps_org
#+BEGIN_SRC python :results table :exports results :eval no
xp2orgtable(MARIADB_XPS)
#+END_SRC

*** Galera experiments                                             :noexport:
Listing [[lst:galera_xps]] shows how to compute the list of experiments
for Galera (~filter(is_galera)~). Table [[tab:galera_xps]] presents the
list of experiments.

#+CAPTION: Access to Galera Experiments.
#+NAME: lst:galera_xps
#+BEGIN_SRC python :results silent
GALERA_XPS = XPS.filter(is_galera).order_by(xp_csize_rtt_b_scn_order)
#+END_SRC

#+HEADER: :colnames yes :hlines yes
#+NAME: lst:galera_xps_org
#+BEGIN_SRC python :results table :exports results :eval no
xp2orgtable(GALERA_XPS)
#+END_SRC

*** CockroachDB experiments                                        :noexport:
Listing [[lst:crdb_xps]] shows how to compute the list of experiments for
CockroachDB (~filter(is_crdb)~). Table [[tab:crdb_xps]] presents the
results.

#+CAPTION: Access to CockroachDB Experiments.
#+NAME: lst:crdb_xps
#+BEGIN_SRC python :results silent
CRDB_XPS = XPS.filter(is_crdb).order_by(xp_csize_rtt_b_scn_order)
#+END_SRC

#+BEGIN_COMMENT
The ~xp2orgtable~ is a [[*Prelude][Prelude]] function that takes a list of ~XP~ and
formats them into an Org table as table [[tab:crdb_xps]].
#+END_COMMENT

#+HEADER: :colnames yes :hlines yes
#+NAME: lst:crdb_xps_org
#+BEGIN_SRC python :results table :exports results :eval no
xp2orgtable(CRDB_XPS)
#+END_SRC

** Query Rally results
The Rally JSON file contains values that give the scenario completion
time per keystone operations at a certain Rally run. These values must
be analyzed to evaluate which backend best suits an OpenStack for the
edge. And a good python module for data analysis is [[https://pandas.pydata.org/][Pandas]]. Thus, the
function ~dataframe_per_operations~ (see lst.
[[lst:dataframe_per_operations]] -- part of [[lst:make_xp][~make_xp~]]) takes the Rally
JSON and returns a Pandas [[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame][~DataFrame~]].

#+CAPTION: Transform Rally Results into Pandas DataFrame.
#+NAME: lst:dataframe_per_operations
#+BEGIN_SRC python :results silent
# Json path to the completion time series
JPATH_SERIES = '$.tasks[0].subtasks[0].workloads[0].data[len(@.error) is 0].atomic_actions'
def dataframe_per_operations(rally_values: objectpath.Tree) -> pd.DataFrame:
    "Makes a 2d pd.DataFrame of completion time per keystone operations."
    df = pd.DataFrame.from_items(
        items=(seq(rally_values.execute(JPATH_SERIES))
               .flatten()
               .group_by(itemgetter('name'))
               .on_value_domap(lambda it: it['finished_at'] - it['started_at'])))
    return df
#+END_SRC

The DataFrame is a table that lists all the completion times in
seconds for a specific Rally scenario. A column references a Keystone
operations and row labels (index) references the Rally run.
Listing\nbsp{}[[lst:crdb_cltenants]] is an example of the DataFrame for
the [[*keystone/create-and-list-tenants]["Create and List Tenants"]] Rally scenario with ~9~ nodes in the
CockroachDB cluster and a ~LAN~ delay between each node. The
src_python[:exports code :eval no]{lambda} line
[[(crdb_cltenants_lambda)]] takes the DataFrame and transforms it to add a
"Total" column. Table [[tab:crdb_cltenants]] presents the output of this
DataFrame.

#+CAPTION: Access to the DataFrame of Rally ~create_and_list_tenants~.
#+NAME: lst:crdb_cltenants
#+BEGIN_SRC python -r -n :results silent
CRDB_CLTENANTS = (XPS
    # Keep xps for Keystone.create_and_list_tenants Rally scenario
    .filter(is_keystone_scn('create_and_list_tenants'))
    # Keep xps for 9 OpenStack instances
    .filter(when_oss(9))
    # Keep xps for CockroachDB backend
    .filter(is_crdb)
    # Keep xps for LAN delay
    .filter(when_delay(0))
    # Keep xps for light load mode
    .filter(compose(not_, is_high))
    # Get dataframe in xp
    .map(attrgetter('dataframe'))
    # Add a Total column
    .map(lambda df: df.assign(Total=df.sum(axis=1))) (ref:crdb_cltenants_lambda)
    .head())
#+END_SRC

#+HEADER: :rownames yes :colnames yes :hlines yes
#+NAME: lst:crdb_cltenants_org
#+BEGIN_SRC python :results table :exports results
df2orgtable(CRDB_CLTENANTS, index_name='Iter')
#+END_SRC

#+CAPTION: Entries for Rally ~create_and_list_tenants~,
#+CAPTION: 9 CRDB nodes, LAN delay.
#+NAME: tab:crdb_cltenants
#+RESULTS: lst:crdb_cltenants_org
| Iter | ~keystone_v3.create_project~ | ~keystone_v3.list_projects~ | Total |
|------+------------------------------+-----------------------------+-------|
|    0 |                        0.134 |                       0.023 | 0.157 |
|    1 |                        0.127 |                       0.025 | 0.152 |
|    2 |                        0.129 |                       0.024 | 0.153 |
|    3 |                        0.134 |                       0.023 | 0.157 |
|    4 |                        0.132 |                       0.024 | 0.156 |
|    5 |                        0.132 |                       0.025 | 0.157 |
|    6 |                        0.126 |                       0.024 | 0.150 |
|    7 |                        0.126 |                       0.026 | 0.153 |
|    8 |                        0.131 |                       0.025 | 0.156 |
|    9 |                        0.130 |                       0.025 | 0.155 |

A pandas DataFrame presents the benefits of efficiently computing a
wide range of analyses. As an example, the listing
[[lst:crdb_cltenants_describe]] computes the number of Rally runs (i.e.,
*count*), mean and standard deviation (i.e., *mean*, *std*), the
fastest and longest completion time (i.e., *min*, *max*), and the
25th, 50th and 75th percentiles (i.e., *25%*, *50%*, *75%*). The
~transpose~ method transposes row labels (index) and columns. Table
[[tab:crdb_cltenants_describe]] presents the output of the analysis.

#+CAPTION: Analyse the DataFrame of Rally ~create_and_list_tenants~.
#+NAME:lst:crdb_cltenants_describe
#+BEGIN_SRC python :results silent
CRDB_CLTENANTS_ANALYSIS = CRDB_CLTENANTS.describe().transpose()
#+END_SRC

#+HEADER: :rownames yes :colnames yes :hlines yes
#+NAME:lst:crdb_cltenants_describe_org
#+BEGIN_SRC python :results table :exports results
df2orgtable(CRDB_CLTENANTS_ANALYSIS, index_name='Operations')
#+END_SRC

#+CAPTION: Analyses of Rally ~create_and_list_tenants~,
#+CAPTION: 9 CRDB nodes, LAN delay.
#+NAME:tab:crdb_cltenants_describe
#+RESULTS: lst:crdb_cltenants_describe_org
| Operations                   |  count |  mean |   std |   min |   25% |   50% |   75% |   max |
|------------------------------+--------+-------+-------+-------+-------+-------+-------+-------|
| ~keystone_v3.create_project~ | 10.000 | 0.130 | 0.003 | 0.126 | 0.128 | 0.131 | 0.132 | 0.134 |
| ~keystone_v3.list_projects~  | 10.000 | 0.024 | 0.001 | 0.023 | 0.024 | 0.024 | 0.025 | 0.026 |
| Total                        | 10.000 | 0.155 | 0.003 | 0.150 | 0.153 | 0.155 | 0.157 | 0.157 |

** Heavy Lifting                                                   :noexport:
Functions that do the heavy lifting for the rest of this study.

*** Predicates
#+NAME: lst:predicate
#+BEGIN_SRC python :results silent
def is_crdb(xp: XP) -> bool:
    "Filter for CockroachDB experiment."
    return xp.rdbms == 'cockroachdb'

def is_galera(xp: XP) -> bool:
    "Filter for Galera experiment."
    return xp.rdbms == 'galera'

def is_mariadb(xp: XP) -> bool:
    "Filter for MariaDB experiment."
    return xp.rdbms == 'mariadb'

def is_high(xp: XP) -> bool:
    "Filter for highed experiment."
    return xp.high

def is_keystone_scn(scn: str) -> bool:
    "Filter for keystone scenario `scn`."
    return lambda xp: xp.scenario == 'KeystoneBasic.' + scn

def when_delay(lat: int) -> Callable[[XP], bool]:
    "Filter for latence `lat`."
    return lambda xp: xp.delay == lat

def when_oss(csize: int) -> Callable[[XP], bool]:
    "Filter for cluster size `csize`."
    return lambda xp: xp.oss == csize

def when_zones(zones: Tuple[str,str,str]) -> Callable[[XP], bool]:
    "Filter for cluster size `csize`."
    return lambda xp: xp.zones == zones

def with_success_rate(rate: float) -> Callable[[XP], bool]:
    "Filter for cluster size `csize`."
    return lambda xp: xp.success >= rate

def xp_csize_rtt_b_scn_order(xp: XP) -> str:
    """
    Returns a comparable value to sort experiments.

    The sort is made on
    1. The database type (CRDB or Galera)
    2. Size of the cluster
    3. Delay
    4. No High, High
    5. Rally scenario's name
    """
    # Format String Syntax
    # https://docs.python.org/2/library/string.html#format-examples
    return f'{xp.rdbms}-{xp.oss:0>3}-{xp.delay:0>3}-{xp.high}-{xp.scenario}'

#+END_SRC

*** High level Queries
#+NAME: lst:hlq
#+BEGIN_SRC python :results silent
def normalize_series(scn: str, s: pd.Series) -> pd.Series:
    "Ensures that all operations of a scenario are present in `s`"
    operations = RALLY[scn]['operations']
    news = pd.Series()
    for op in operations:
        if op in s.index:
            news = news.append(s.loc[[op]])
        else:
            print("in noramlization")
            news = news.append(pd.Series({op: np.nan}))
    return news

def make_series(scn: 'xp.scenario') -> pd.Series:
    "Builds a pd.Series with operations of `scn` in index"
    operations = RALLY[scn]['operations']
    return pd.Series(np.nan, index=operations)

def make_dataframe(scn: 'xp.scenario') -> pd.DataFrame:
    "Builds a pd.DataFrame with operations of `scn` in column"
    operations = RALLY[scn]['operations']
    iterations = RALLY[scn]['iterations']
    # Prefer from_items rather than from_dict to preserver order
    # of operations
    return pd.DataFrame.from_items([
        (op, pd.Series(np.nan, index=range(iterations))) for op in  operations
    ])

def make_xps(scn, rdbms, oss, delay, high, zones, number) -> List['XP']:
    "Builds a list with `number` crashed XP"
    df = make_dataframe(scn)
    return [ XP(scenario=scn, filepath='', rdbms=rdbms, oss=oss,
                delay=delay, success=0, high=high, zones=zones,
                dataframe=df)
             for i in range(number) ]

def add_total_column(df: pd.DataFrame) -> pd.DataFrame:
    "Adds the Total column that sum values of all columns"
    return df.assign(Total=df.sum(axis='columns'))

def filter_percentile(q: float, df: pd.DataFrame) -> pd.DataFrame:
    "Removes values upper than percentile `q` of a Rally based DataFrame"
    # Unused (keep for legacy purpose):
    def find_column_with_biggest_impact(df: pd.DataFrame) -> str:
        "Returns the column's name with values that most impacts the plot crushing"
        return df.std().idxmax()
    # Real code is here:
    df_with_total = add_total_column(df)
    percentile = df_with_total.quantile(q)['Total']
    new_df = df_with_total[df_with_total['Total'] < percentile]
    return new_df.drop('Total', axis='columns')

def filter_percentile_(q: float) -> Callable[[pd.DataFrame], pd.DataFrame]:
    return lambda df: filter_percentile(q, df)

def reify_in_xpdf(attr: str) -> Callable[[XP], XP]:
    "Pushes `XP.attr` attribute value into `XP.dataframe` under `attr` column"
    # Curry
    def _push(xp: XP) -> XP:
        column_value = attrgetter(attr)(xp)
        column_name  = attr
        df_with_new_col = df_add_const_column(xp.dataframe, column_value, column_name)
        return set_xp_df(xp, df_with_new_col)
    #
    return _push

def results_per_scn_attr(attr: str, xps: List[XP]) -> List[
        Tuple[str, pd.DataFrame, pd.DataFrame]]:
    return (xps
            # Index XPs by scenario: [(scenario, [xps-csize{3/25/45}-lat0])]
            .group_by(attrgetter('scenario'))
            # Push values of `xp.attr` and `xp.rdbms` in the
            # dataframe. And only keep values under the 90th
            # percentile.
            .on_value_domap(reify_in_xpdf(attr))
            .on_value_domap(reify_in_xpdf('rdbms'))
            .on_value_domap(attrgetter('dataframe'))
            .on_value_domap(filter_percentile(.95))
            # Get one big DataFrame per scenario:
            # [(scenario, df{keystone.op1, keystone.op2, ..., oss, rdbms})]
            .on_value(lambda dfs: pd.concat(dfs.to_list()))
            # Groupe by `xp.rdbms` and `xp.attr`, to compute the mean
            # and std of each group:
            .on_value(lambda df: df.groupby(['rdbms', attr]))
            # Returns this as a triplet: (scn, df_mean, df_std)
            .map(lambda scn_gdf: (
                scn_gdf[0],
                scn_gdf[1].aggregate('mean'),
                scn_gdf[1].apply(lambda df: df.sum(axis=1).std())))
          )

def scn_mean_std(obj: Tuple['scenario', pd.DataFrame]) -> Tuple[
        'scenario', pd.DataFrame, pd.DataFrame]:
    scn, gdf = obj
    return (scn, gdf.aggregate('mean'), gdf.apply(lambda df: df.sum(axis=1).std()))
#+END_SRC

*** Ploting results
**** Trend Plotting
#+BEGIN_SRC python :results silent
def series_stackedbar_plot(scn: 'xp.scenario',
                           ops_std_succ: Dict['xp.attr',
                               Tuple['pd.Series/median', 'float/std', 'float/success']],
                           ax: matplotlib.axes.Axes):
    """Vertical bar plot of a dict of pd.Series.

    Vertiacal bar plot pushses all series of one dict key in one bar
    (e.g., one bar for a cluster size of 3, one bar for a cluster size
    of 9, and one bar for a cluster size of 45) . The bar is divided
    in mutiple parts that depict the value of each operation (e.g.,
    keystone.create_user and keystone.update_user).
    """
    # Bars in the plot are keys in the Dict (eg, 3, 25, 45 or 0, 50,
    # 150).
    bars = list(ops_std_succ.keys())
    nb_bars = len(bars)
    # Size of a bar is 100% of the x view divided by the number of bar.
    bar_width = 1.0/nb_bars
    bar_index = [ i * bar_width for i in range(nb_bars) ]
    # Put on tick per bar on x axis
    ax.set_xticks(bar_index)
    ax.set_xticklabels(bars)
    # Make a datafram with results, e.g.,
    #                                   3         9         45
    # keystone_v3.create_project  0.137284  0.145858  0.154108
    # keystone_v3.create_user     0.176240  0.183208  0.196593
    # keystone_v3.create_role     0.031082  0.031126  0.034259
    # keystone_v3.get_project     0.020774  0.020956  0.022913
    # keystone_v3.get_user        0.020317  0.020496  0.022833
    # keystone_v3.get_role        0.020130  0.020629  0.022903
    # keystone_v3.list_services   0.023072  0.023743  0.026078
    # keystone_v3.get_services    0.020144  0.020214  0.022274
    df  = pd.DataFrame.from_items([ (k, mean) for k, (mean, std, succ) in ops_std_succ.items() ])
    successes = [ succ for k, (mean, std, succ) in ops_std_succ.items() ]
    stds = [ std for k, (mean, std, succ) in ops_std_succ.items() ]
    # Plots operation one after the other (stacked). The plot is made
    # by calling `ax.bar` with all values of the first scn's operation
    # (e.g., create_project), then, all values of the second scn's
    # operation (e.g., create_user), and so on, until the last row
    # (e.g., get_services).
    #
    for iop, op in enumerate(RALLY[scn]['operations']):
        # Stack values on top of the previous ops
        previous_ops = None if iop == 0 else df.loc[:df.index[iop - 1]].sum(axis='index')
        # Plot
        rects = ax.bar(bar_index, df.loc[op].values, bar_width,
                       bottom=previous_ops, label=op)
    #
    # Add success rate on top of the last operation
    for irect, rect in enumerate(rects):
        x = rect.get_x() + rect.get_width()*0.5
        y = rect.get_y() + rect.get_height()*1.01 if rect.get_y() > 0 else 0
        fail = round(1.0 - successes[irect], 2) if not np.isnan(successes[irect]) else 'NaN'
        std = round(stds[irect], 2)
        ax.text(x, y, f'σ: {std}, λ: {fail}', ha='center', va='bottom', size='x-small')

def series_linear_plot(scn: 'xp.scenario',
                       cfs: Dict['xp.attr', pd.Series],
                       ax: matplotlib.axes.Axes):
    """Linear bar plot of a dict of pd.Series.
    """
    # Plots lines one after the other. made by calling `ax.bar` with
    # all values of the experiment, then, all values of the second,
    # and so on, until the last row.
    for i, (attr, cf) in enumerate(cfs.items()):
        linestyle = linestyles[i % len(linestyles)]
        ax.plot(cf, drawstyle='steps', linestyle=linestyle, label=attr)

def series_lreg_plot(scn: 'xp.scenario',
                     ss: Dict['xp.attr', Union[pd.Series, None]],
                     ax: matplotlib.axes.Axes):
    normalized_ss = {}
    x = []
    y = []
    for attr, s in ss.items():
        normalized_s = s if s is not None else pd.Series(np.nan, index=range(10))
        for i in range(len(normalized_s)):
            x.append(attr)
        for e in normalized_s.values:
            y.append(e)
    #
    ax.scatter(x, y, marker='+')
    #
    z = np.polyfit(x, y, 1)
    p = np.poly1d(z)
    ax.plot(x,p(x))
#+END_SRC

**** Frame Plotting
#+BEGIN_SRC python :results silent
def frame_plot(K: 'xp.attr'):
    def frame_plot_(ytitle: str,
                    plot: Callable[['xp.scenario',
                                    Dict['xp.attr', T],
                                    matplotlib.axes.Axes], None],
                    filepath: str,
                    xps: Dict[Tuple['xp.scenario', 'xp.rdbms', 'xp.oss'], T],
                    legend: Union['out', 'outright', 'all'] = 'out',
                    orientation: Union['portrait', 'landscape'] = 'portrait'):
        scns = sorted(   # the list of scenarios
            set(map(itemgetter(0), xps.keys())),
            key=lambda scn: list(RALLY.keys()).index(scn))
        subfig_width  = 4 # inch
        subfig_height = 4 # inch
        nscns  = len(scns)   # Number of scenarios
        nrdbms = len(RDBMSS) # Number of rdbms
        nrows = nrdbms if orientation == 'portrait' else nscns
        ncols = nscns  if orientation == 'portrait' else nrdbms
        sharexy = 'col' if orientation == 'portrait' else 'row'
        fig, axs = plt.subplots(nrows=nrows,
                                ncols=ncols,
                                figsize=(subfig_width  * ncols,
                                         subfig_height * nrows),
                                tight_layout=True,
                                sharex=sharexy,
                                sharey=sharexy)
        #
        # Normalize the form of an axs object in case of only one
        # scenario
        if nscns == 1:
            axs_prim = []
            if orientation == 'portrait':
                for irdbms, rdbms in enumerate(RDBMSS):
                    axs_prim.append([axs[irdbms]])
            else:
                axs_prim.append(axs)
            #
            axs = axs_prim
        #
        # Subplots for sncs x rdmbss
        scns_rdbmss = [ (s, r) for s in enumerate(scns) for r in enumerate(RDBMSS) ]
        for (iscn, scn), (irdbms, rdbms) in scns_rdbmss:
            # Get subplot for `scn` and `rdbms`
            if orientation == 'portrait':
                ax = axs[irdbms][iscn]
            else:
                ax = axs[iscn][irdbms]
            #
            # Get all experiments for `scn` and `rdbms`, indexed by `K`
            k_xps = {k : xps.get((scn, rdbms, k)) for k in K}
            #
            # Plot
            plot(scn, k_xps, ax)
            #
            # Only print y label for the first column
            if iscn == 0:
                ax.set_ylabel(ytitle % rdbms.title())
            #
            # Only print scenario name for the first row
            if irdbms == 0 :
                fig_title = (f'{scn.title()} (%reads: {RALLY[scn]["%reads"]}, %writes: {RALLY[scn]["%writes"]})'
                             .replace('Keystonebasic.', '')
                             .replace('_', ' '))
                if orientation == 'portrait':
                    fig_title = textwrap.shorten(
                        fig_title,
                        width=30,
                        placeholder='...')
                #
                if nscns == 1 and orientation == 'landscape':
                    # fig.suptitle(fig_title)
                    pass
                else:
                    ax.set_title(fig_title, loc='left')
            #
            # Remove x label except for the last row
            if orientation == 'portrait' and irdbms != len(RDBMSS) - 1:
                plt.setp(ax.get_xticklabels(), visible=False)
            #
            # Legend at the bottom of the view on the last row for
            # portrait orientation
            if legend == 'out' and orientation == 'portrait' and irdbms == len(RDBMSS) - 1:
                box = ax.get_position()
                ax.set_position([box.x0, box.y0 + box.height * 0.1,
                                 box.width, box.height * 0.9])
                ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1))
            #
            # Legend at the left of the view for landscape orientation
            if legend == 'out' and orientation == 'landscape' and irdbms == 0:
                ax.legend(loc='best')
            # #
            # # Legend at the left of the view for landscape orientation
            # if legend == 'out' and orientation == 'landscape' and irdbms == 0:
            #     ax.legend(loc='upper left')
            # #
            # # Legend at the right of the view for landscape orientation
            # if legend == 'out right' and orientation == 'landscape' and irdbms == 0:
            #     ax.legend(loc='lower right')
            #
            # Legend on all plot
            if legend == 'all':
                ax.legend(loc='lower right')
        #
        fig.align_labels()
        return savefig(fig, filepath)
    return frame_plot_

oss_plot = frame_plot(OSS)
delay_plot = frame_plot(DELAYS)
#+END_SRC

* Experiment Analysis (skip to this section to see results)
This section presents the results of experiments and their analysis.
To avoid lengths of graphics in this report, only a short version of
the results are presented. The entirety of the results, that is,
median time for each Rally scenarios and cumulative distribution
functions for each scenarios, are located in the appendix (see, [[*Detailed experiments
 results][Detailed experiments results]]).

The short results focus on two Rally scenarios. First, /[[*keystone/authenticate-user-and-validate-token][authenticate
and validate a keystone token (%reads: 96.46, %writes: 3.54)]]/, which
represents more than 95% of what is actually done on a running
Keystone. Second, /[[*keystone/create-user-update-password][create user and update password for that user
(%reads: 89.79, %writes: 10.21)]]/, which gets the highest rate of
writes and thus, the most likely to produce contention on the RDBMS.

In next result plots, the /λ/ Greek letter stands for the failure rate
and /σ/ for the standard deviation.

** Results access                                                 :noexport:
Snippet code to get access to the results

*** Experiments for number of OpenStack instances impact ~lst:xps_oss~
#+NAME: lst:xps_oss
#+BEGIN_SRC python :eval no
XPS
# We are only interested in results where delay is LAN
.filter(when_delay(0))
# remove values greater than the 95th percentile
.map(lambda xp: xp.set_dataframe(filter_percentile(.95, xp.dataframe)))
#+END_SRC

*** Experiments for delay impact ~lst:xps_delay~
#+NAME: lst:xps_delay
#+BEGIN_SRC python :eval no
XPS
# We are only interested in results with 9 OpenStack instances
.filter(when_oss(9))
.filter(compose(not_, when_delay(10)))
# Also, remove values greater than the 95th percentile
.map(lambda xp: xp.set_dataframe(filter_percentile(.95, xp.dataframe)))
#+END_SRC

*** Median completion time ~lst:median_ctime~
:PROPERTIES:
:header-args: :noweb-ref lst:median_ctime :eval no
:END:
Code to compute the median completion time of each rally scenarios.


Only keep dataframe and success for each XP
#+BEGIN_SRC python
.on_value_domap(lambda xp: (xp.dataframe, xp.success))
#+END_SRC

#+RESULTS:

Get one big DataFrame with results of all runs: ~[((scenario, rdbms,
oss), df{keystone.op1: [...], keystone.op2: [...], ...}, %success)]~
#+BEGIN_SRC python
.on_value(unpack(lambda dfs, succs: (pd.concat(dfs), np.mean(succs))))
#+END_SRC

#+RESULTS:

Compute the median, std and success of all iterations: ~[((scenario,
rdbms, oss), df{keystone.op1: α, keystone.op2: β, ...}, %success)]~
#+BEGIN_SRC python
.on_value(unpack(lambda df, succ: (df.mean(), df.sum(axis=1).std(), succ)))
#+END_SRC

#+RESULTS:

Finally, make a dict: ~[{(scenario, rdbms, oss): (df{keystone.op1: α,
keystone.op2: β, ...}, %success)}]~
#+BEGIN_SRC python
.to_dict()
#+END_SRC

#+RESULTS:

*** Cumulative Distribution Function ~lst:cdf~
:PROPERTIES:
:header-args: :noweb-ref lst:cdf :eval no
:END:
Code to compute the cumulative distribution function of each rally
scenarios.

Only keep dataframe for each XP
#+BEGIN_SRC python
.on_value_domap(attrgetter('dataframe'))
#+END_SRC

#+RESULTS:

Get one big DataFrame with results of all runs: ~[((scenario, rdbms,
oss), df{keystone.op1: [...], keystone.op2: [...], ...})]~
#+BEGIN_SRC python
.on_value(lambda dfs: pd.concat(dfs))
#+END_SRC

#+RESULTS:

Sum all iterations: ~[((scenario, rdbms, oss), sum)]~, and compute the
cdf: ~[((scenario, rdbms, oss), cdf)]~
#+BEGIN_SRC python
.on_value(lambda df: df.sum(axis='columns'))
.on_value(make_cumulative_frequency)
#+END_SRC

#+RESULTS:

Finally, make a dict: ~[{(scenario, rdbms, oss): cdf}]~
#+BEGIN_SRC python
.to_dict()
#+END_SRC

#+RESULTS:

*** Linear Regression ~lst:lreg~
:PROPERTIES:
:header-args: :noweb-ref lst:lreg :eval no
:END:

#+BEGIN_SRC python
.on_value_domap(attrgetter('dataframe'))
.on_value(lambda dfs: pd.concat(dfs))
.on_value(lambda df: df.sum(axis='columns'))
.to_dict()
#+END_SRC

#+RESULTS:

** Number of OpenStack instances impact
This test evaluates how the completion time of Rally Keystone's
scenarios varies, depending on the RDBMS and the number of OpenStack
instances. It measure the capacity of a RDBMS to handle lot of
connections and requests. In this test, the number of OpenStack
instances varies between ~3~, ~9~ and ~45~ and a ~LAN~ link
inter-connects instances. As explain in the [[*OpenStack at the Edge: the Keystone Use-Case][OpenStack at the Edge]]
section, the deployment of the database depends on the RDBMS. With
MariaDB, one instance of OpenStack contains the database, and others
connect to that one. For Galera and CockroachDB, every OpenStack
contains an instance of the RDBMS.

For these experiments, Juice deployed database together with OpenStack
instances and plays Rally scenarios listed in section [[*List of Rally scenarios][List of Rally
scenarios]]. Juice runs Rally scenarios under both light and high load.
Results are presented in the two next subsections. The Juice
implementation for these experiments is available on GitHub at
[[https://github.com/BeyondTheClouds/juice/blob/8dc04c7fbd371f441f76b3ff73a9a55530b172e4/experiments/cluster-size-impact.py][experiments/cluster-size-impact.py]].

*** Authenticate and validate a Keystone token (%r: 96.46, %w: 3.54)
Figure [[fig:xps_oss_auth_light]] plots the mean completion time (in
second) of Keystone /authenticate and validate a keystone token (%r:
96.46, %w: 3.54)/ scenario in a light Rally mode. The plot displays
results in three tiles. The first tile shows completion time with the
centralized MariaDB, second tile with the replicated Galera and, third
tile with the global CockroachDB. A tile presents results with stacked
bar charts. A bar depicts the total completion time for a specific
number of OpenStack instances (/i.e./, ~3~, ~9~ and ~45~) and stacks
completion times of each Keystone operations. The figure shows that
the trend is similar for the three RDBMS, to the advantage of the
centralized MariaDB, followed by Galera and then CockroachDB.

#+NAME: lst:xps_oss_auth_light
#+BEGIN_SRC python :results file :noweb yes :exports results
oss_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/oss-impact-auth-light',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter light load
          .filter(compose(not_, is_high))
          # Only keep KeystoneBasic.authenticate_user_and_validate_token
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the median and the std of the results
          <<lst:median_ctime>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_oss_auth_light
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_auth_light
[[file:imgs/oss-impact-auth-light.png]]


Figure [[fig:xps_oss_auth_high]] shows that putting pressure using the
high load has strong effects on MariaDB and Galera while CockroachDB
well handles it. With 45 OpenStack instances, the failure rate of
MariaDB rises from 0 to 98 percent (/i.e./, λ: 0.98) and, the mean
completion time of Galera rises from 120 to 475 milliseconds (namely,
an increased by a factor of 4).

#+NAME: lst:xps_oss_auth_high
#+BEGIN_SRC python :results file :noweb yes :exports results
oss_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/oss-impact-auth-high',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter high load
          .filter(is_high)
          # Only keep KeystoneBasic.authenticate_user_and_validate_token
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the median and the std of the results
          <<lst:median_ctime>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_oss_auth_high
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_auth_high
[[file:imgs/oss-impact-auth-high.png]]

TODO:explenation (look at MariaDB log).

TODO:explenation (look at Galera log). Plotting the cumulative
distribution function (/i.e./, the probability that the scenario
complete in less or equal than a certain time -- see,
fig. [[fig:xps_oss_auth_high_cdf]]) shows that, with 45 OpenStack
instances, more than 95% of the results should complete in a
reasonable time, but the lasts 5% may take a really long time to
complete (here, up to 30 second).

#+NAME: lst:xps_oss_auth_high_cdf
#+BEGIN_SRC python :results file :noweb yes :exports results
oss_plot("%s Cumulative Percent",
         series_linear_plot,
         'imgs/oss-impact-auth-high-cdf',
         (# -- Experiment selection
          <<lst:xps_oss>>
          # Filter high load
          .filter(is_high)
          # Only keep KeystoneBasic.authenticate_user_and_validate_token
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the cdf
          <<lst:cdf>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54)
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_oss_auth_high_cdf
#+ATTR_ORG: :width 50
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_oss_auth_high_cdf
[[file:imgs/oss-impact-auth-high-cdf.png]]

**** COMMENT Linear Regression
Linear Regression Light
#+NAME: lst:xps_oss_auth_light_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
oss_plot("%s Completion Time (s)",
         series_lreg_plot,
         'imgs/oss-impact-auth-light-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_oss>>
          .filter(compose(not_, is_high))
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54) --
#+CAPTION: Linear Regression.
#+NAME: fig:xps_oss_auth_light_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_auth_light_lreg
[[file:imgs/oss-impact-auth-light-lreg.png]]

Linear Regression High
#+NAME: lst:xps_oss_auth_high_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
oss_plot("%s Completion Time (s)",
         series_lreg_plot,
         'imgs/oss-impact-auth-high-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_oss>>
          .filter(is_high)
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54) --
#+CAPTION: Linear Regression.
#+NAME: fig:xps_oss_auth_high_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_auth_high_lreg
[[file:imgs/oss-impact-auth-high-lreg.png]]

*** Create a user and update her password (%r: 89.79, %w: 10.21)
Figure [[fig:xps_oss_auth_light]] plots the mean completion time (in
second) of Keystone /Create a user and update her password (%r: 89.79,
%w: 10.21)/ scenario in a light Rally mode.

#+NAME: lst:xps_oss_pwd_light
#+BEGIN_SRC python :results file :noweb yes :exports results
oss_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/oss-impact-pwd-light',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter light load
          .filter(compose(not_, is_high))
          # Only keep KeystoneBasic.create_user_update_password
          .filter(is_keystone_scn('create_user_update_password'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the median and the std of the results
          <<lst:median_ctime>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_oss_pwd_light
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_pwd_light
[[file:imgs/oss-impact-pwd-light.png]]

High mode
#+NAME: lst:xps_oss_pwd_high
#+BEGIN_SRC python :results file :noweb yes :exports results
oss_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/oss-impact-pwd-high',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter high load
          .filter(is_high)
          # Only keep KeystoneBasic.create_user_update_password
          .filter(is_keystone_scn('create_user_update_password'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the median and the std of the results
          <<lst:median_ctime>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_oss_pwd_high
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_pwd_high
[[file:imgs/oss-impact-pwd-high.png]]


CDF
#+NAME: lst:xps_oss_pwd_high_cdf
#+BEGIN_SRC python :results file :noweb yes :exports results
oss_plot("%s Cumulative Percent",
         series_linear_plot,
         'imgs/oss-impact-pwd-high-cdf',
         (# -- Experiment selection
          <<lst:xps_oss>>
          # Filter high load
          .filter(is_high)
          # Only keep KeystoneBasic.create_user_update_password
          .filter(is_keystone_scn('create_user_update_password'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the cdf
          <<lst:cdf>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21)
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_oss_pwd_high_cdf
#+ATTR_ORG: :width 50
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_oss_pwd_high_cdf
[[file:imgs/oss-impact-pwd-high-cdf.png]]

**** COMMENT Linear Regression
Linear Regression Light
#+NAME: lst:xps_oss_pwd_light_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
oss_plot("%s Completion Time (s)",
         series_lreg_plot,
         'imgs/oss-impact-pwd-light-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_oss>>
          .filter(compose(not_, is_high))
          .filter(is_keystone_scn('create_user_update_password'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21) --
#+CAPTION: Linear Regression.
#+NAME: fig:xps_oss_pwd_light_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_pwd_light_lreg
[[file:imgs/oss-impact-pwd-light-lreg.png]]

Linear Regression High
#+NAME: lst:xps_oss_pwd_high_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
oss_plot("%s",
         series_lreg_plot,
         'imgs/oss-impact-pwd-high-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_oss>>
          .filter(is_high)
          .filter(is_keystone_scn('create_user_update_password'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances
#+CAPTION: on the Completion Time under High Load
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21) --
#+CAPTION: -- Linear Regression.
#+NAME: fig:xps_oss_pwd_high_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_pwd_high_lreg
[[file:imgs/oss-impact-pwd-high-lreg.png]]

*** Scale outline
TODO:

#+CAPTION: Scale of a RDBMS with the Number OpenStack instances
#+NAME: tab:scale_outline
| RDBMS       | Scale | Note |
|-------------+-------+------|
| MariaDB     | 😺️    |      |
| Galera      | 😾️    |      |
| CockroachDB | 😺    |      |

** Delay impact
In this test, the size of the database cluster is 9 and the delay
varies between LAN, 100 and 300 ms of RTT. The test evaluates how the
completion time of Rally scenarios varies, depending of RTT between
nodes of the swarm.

- TODO: describe the experimentation protocol
- TODO: Link the github juice code

*** COMMENT Throughput expectations
See [[http://enos.irisa.fr/html/wan_g5k/cpt10/][cpt10-lat*-los0/*.stats]] for raw measures.

#+NAME: throughput-data
#+CAPTION: Throughput Expectations
| Delay (ms) | Throughput (Mbits/s) |
|--------------+----------------------|
|     0.150614 |          9410.991784 |
|    20.000000 |          1206.381685 |
|    50.000000 |           480.173601 |
|   100.000000 |           234.189943 |
|   200.000000 |           115.890071 |

*** Authenticate and validate a Keystone token (%r: 96.46, %w: 3.54)
Auth. Light Mode

#+NAME: lst:xps_delay_auth_light
#+BEGIN_SRC python :results file :noweb yes :exports results
delay_plot("%s Completion Time (s)",
           series_stackedbar_plot,
           'imgs/delay-impact-auth-light',
           (# -- Experiments selection
            <<lst:xps_delay>>
            # Filter light load
            .filter(compose(not_, is_high))
            # Only keep KeystoneBasic.authenticate_user_and_validate_token
            .filter(is_keystone_scn('authenticate_user_and_validate_token'))
            # Group results by scenario's name, RDBMS technology and
            # number of OpenStack instances.
            .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
            # Compute the median and the std of the results
            <<lst:median_ctime>>),
           orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under Light Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_delay_auth_light
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_delay_auth_light
[[file:imgs/delay-impact-auth-light.png]]

High Mode

#+NAME: lst:xps_delay_auth_high
#+BEGIN_SRC python :results file :noweb yes :exports results
delay_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/delay-impact-auth-high',
         (# -- Experiments selection
          <<lst:xps_delay>>
          # Filter high load
          .filter(is_high)
          # Only keep KeystoneBasic.authenticate_user_and_validate_token
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          # Compute the median and the std of the results
          <<lst:median_ctime>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under High Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_delay_auth_high
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_delay_auth_high
[[file:imgs/delay-impact-auth-high.png]]

CDF

#+NAME: lst:xps_delay_auth_high_cdf
#+BEGIN_SRC python :results file :noweb yes :exports results
delay_plot("%s Cumulative Percent",
           series_linear_plot,
           'imgs/delay-impact-auth-high-cdf',
           (# -- Experiment selection
            <<lst:xps_delay>>
            # Filter high load
            .filter(is_high)
            # Only keep KeystoneBasic.authenticate_user_and_validate_token
            .filter(is_keystone_scn('authenticate_user_and_validate_token'))
            # Group results by scenario's name, RDBMS technology and
            # number of OpenStack instances.
            .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
            # Compute the cdf
            <<lst:cdf>>),
           orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under High Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54)
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_delay_auth_high_cdf
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_delay_auth_high_cdf
[[file:imgs/delay-impact-auth-high-cdf.png]]

**** COMMENT Linear Regression
Linear Regression Light
#+NAME: lst:xps_delay_auth_light_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
delay_plot("%s Completion Time (s)",
         series_lreg_plot,
         'imgs/delay-impact-auth-light-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_delay>>
          .filter(compose(not_, is_high))
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54) --
#+CAPTION: Linear Regression.
#+NAME: fig:xps_delay_auth_light_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_auth_light_lreg
[[file:imgs/delay-impact-auth-light-lreg.png]]

Linear Regression High
#+NAME: lst:xps_delay_auth_high_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
delay_plot("%s Completion Time (s)",
         series_lreg_plot,
         'imgs/delay-impact-auth-high-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_delay>>
          .filter(is_high)
          .filter(is_keystone_scn('authenticate_user_and_validate_token'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load for scenario
#+CAPTION: Authenticate and Validate a Keystone Token (%r: 96.46, %w: 3.54) --
#+CAPTION: Linear Regression.
#+NAME: fig:xps_delay_auth_high_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_auth_high_lreg
[[file:imgs/delay-impact-auth-high-lreg.png]]

*** Create a user and update her password (%r: 89.79, %w: 10.21)
Create Light Mode

#+NAME: lst:xps_delay_pwd_light
#+BEGIN_SRC python :results file :noweb yes :exports results
delay_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/delay-impact-pwd-light',
         (# -- Experiments selection
          <<lst:xps_delay>>
          # Filter light load
          .filter(compose(not_, is_high))
          # Only keep KeystoneBasic.create_user_update_password
          .filter(is_keystone_scn('create_user_update_password'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          # Compute the median and the std of the results
          <<lst:median_ctime>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under Light Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_delay_pwd_light
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_pwd_light
[[file:imgs/delay-impact-pwd-light.png]]

High Mode

#+NAME: lst:xps_delay_pwd_high
#+BEGIN_SRC python :results file :noweb yes :exports results
delay_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/delay-impact-pwd-high',
         (# -- Experiments selection
          <<lst:xps_delay>>
          # Filter high load
          .filter(is_high)
          # Only keep KeystoneBasic.create_user_update_password
          .filter(is_keystone_scn('create_user_update_password'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          # Compute the median and the std of the results
          <<lst:median_ctime>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under High Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21)
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_delay_pwd_high
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_pwd_high
[[file:imgs/delay-impact-pwd-high.png]]

CDF

#+NAME: lst:xps_delay_pwd_high_cdf
#+BEGIN_SRC python :results file :noweb yes :exports results
delay_plot("%s Cumulative Percent",
         series_linear_plot,
         'imgs/delay-impact-pwd-high-cdf',
         (# -- Experiment selection
          <<lst:xps_delay>>
          # Filter high load
          .filter(is_high)
          # Only keep KeystoneBasic.create_user_update_password
          .filter(is_keystone_scn('create_user_update_password'))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          # Compute the cdf
          <<lst:cdf>>),
         orientation = 'landscape')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under High Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21)
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_delay_pwd_high_cdf
#+ATTR_ORG: :width 50
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_delay_pwd_high_cdf
[[file:imgs/delay-impact-pwd-high-cdf.png]]

**** COMMENT Linear Regression
Linear Regression Light
#+NAME: lst:xps_delay_pwd_light_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
delay_plot("%s Completion Time (s)",
         series_lreg_plot,
         'imgs/delay-impact-pwd-light-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_delay>>
          .filter(compose(not_, is_high))
          .filter(is_keystone_scn('create_user_update_password'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load for scenario
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21) --
#+CAPTION: Linear Regression.
#+NAME: fig:xps_delay_pwd_light_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_pwd_light_lreg
[[file:imgs/delay-impact-pwd-light-lreg.png]]

Linear Regression High
#+NAME: lst:xps_delay_pwd_high_lreg
#+BEGIN_SRC python :results file :exports results :noweb yes
delay_plot("%s Completion Time (s)",
         series_lreg_plot,
         'imgs/delay-impact-pwd-high-lreg',
         # Compute the mean and the std of the results
         (
          <<lst:xps_delay>>
          .filter(is_high)
          .filter(is_keystone_scn('create_user_update_password'))
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
          <<lst:lreg>>
          ),
         orientation='landscape')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances
#+CAPTION: on the Completion Time under High Load
#+CAPTION: Create a User and Update Her Password (%r: 89.79, %w: 10.21) --
#+CAPTION: -- Linear Regression.
#+NAME: fig:xps_delay_pwd_high_lreg
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_pwd_high_lreg
[[file:imgs/delay-impact-pwd-high-lreg.png]]

*** Network delay outline
TODO:

#+CAPTION: RDBMS Handling of Network Delay
#+NAME: tab:delay_outline
| RDBMS       | Network Delay       | Note |
|-------------+---------------------+------|
| MariaDB     | 😺                  |      |
| Galera      | 😺 reads, 😾 writes |      |
| CockroachDB | 😾                  |      |

** Taking into account the user locality
A homogeneous delay is sometimes needed but does not map to the edge
reality where some nodes are closed and other are far. To simulate
such heterogeneous network infrastructure ...

#+CAPTION: Replication Zones.
#+NAME: lst:rzones
#+BEGIN_SRC python :results silent
ZONES = [ ('Z1', 'Z2', 'Z3'), ('Z1', 'Z1', 'Z3'),  ('Z1', 'Z1', 'Z1') ]
#+END_SRC

#+CAPTION: ~XP~ property for Replication Zones
#+NAME: lst:xp_zones
#+BEGIN_SRC python :results silent
zones: Tuple[str,str,str] = ('Z1', 'Z1', 'Z1') # Replication Zones
#+END_SRC

#+CAPTION: Parsing of replication zones
#+NAME: lst:make_xp_zones
#+BEGIN_SRC python :eval no
zones = tuple([xp_info.get('zones')[x:x+2] for x in range(0, len(xp_info.get('zones')), 2)]),
#+END_SRC

#+BEGIN_SRC python :results silent
zones_plot = frame_plot(ZONES)
#+END_SRC

*** Delay distribution: uniform & hierarchical
This study considers two kinds of OpenStack instances deployments.
This first one, called /uniform/, defines a uniform distribution of
the network latency between OpenStack instances. For instance, ~300~
ms of RTT between all the ~9~ OpenStack instances. The second
deployment, called /hierarchical/, maps to a more realistic view, like
in cloud computing, with groups of OpenStack instances connected
through a low latency network (/e.g./, ~3~ OpenStack instances per
group deployed in the same country, and accessible within ~20~ ms of
RTT). And high latency network between groups (/e.g./ ~150~ ms of RTT
between groups deployed in different countries).


#+BEGIN_SRC python :results silent
XPS_ZONES = (XPS
    # We are only interested in results with 9 OpenStack instances
    .filter(when_oss(9))
    .filter(when_delay(10))
    .filter(compose(not_, is_high))
    # .filter(is_keystone_scn('get_entities'))
    # .filter(is_crdb)
    # Also, remove values greater than the 95th percentile
    .map(lambda xp: xp.set_dataframe(filter_percentile(.95, xp.dataframe)))
)
#+END_SRC

#+NAME: lst:xps_zones_light
#+BEGIN_SRC python :results file :exports results
zones_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/zones-impact-light',
         (XPS_ZONES
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.zones))
          .on_value_domap(lambda xp: (xp.dataframe, xp.success))
          .on_value(unpack(lambda dfs, succs: (pd.concat(dfs), np.mean(succs))))
          .on_value(unpack(lambda df, succ: (df.median(), df.sum(axis=1).std(), succ)))
          .to_dict()))
#+END_SRC

#+CAPTION: Impact of the Data Locality
#+CAPTION: on the Completion Time under Light Load
#+CAPTION: -- Median Time for Each Operations.
#+NAME: fig:xps_zones_light
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_zones_light

CDF

#+NAME: lst:xps_zones_light_cdf
#+BEGIN_SRC python :results file :exports results
def make_cumulative_frequency(s: pd.Series) -> pd.Series:
    "Performed a Cumulative Frequency Analysis"
    cum_dist = np.linspace(0.,1.,len(s))
    return pd.Series(cum_dist, index=s.sort_values())

zones_plot("%s",
         series_linear_plot,
         'imgs/zones-impact-light-cdf',
         # Compute the mean and the std of the results
         (XPS_ZONES
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.zones))
          .on_value_domap(attrgetter('dataframe'))
          .on_value(lambda dfs: pd.concat(dfs))
          .on_value(lambda df: df.sum(axis='columns'))
          .on_value(make_cumulative_frequency)
          .to_dict()),
         legend='all')
#+END_SRC

#+CAPTION: Impact of the Data Locality
#+CAPTION: on the Completion Time under Light Load
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_zones_light
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_zones_light_cdf

*** Locality outline

#+CAPTION: RDBMS Handling of Network Delay with Locality
#+NAME: tab:locality_outline
| RDBMS       | Network Delay w/ Locality | Note |
|-------------+---------------------------+------|
| MariaDB     | 😺                        |      |
| Galera      | 😺 reads, 😾 writes       |      |
| CockroachDB | 😺                        |      |

* Experiments Outline
TODO:

#+CAPTION: RDBMS for Large Geo-Distributed OpenStacks
#+NAME: tab:openstack_outline
| RDBMS       | Scale | Network Delay                  | Note |
|-------------+-------+--------------------------------+------|
| MariaDB     | 😺    | 😺                             |      |
| Galera      | 😾    | 😺 reads, 😾 writes            |      |
| CockroachDB | 😺    | 😺 with locality, 😾 otherwise |      |


TODO: General purpose support of locality

* COMMENT Do the size of the Database matter?
From
http://galeracluster.com/2016/08/optimized-state-snapshot-transfers-in-a-wan-environment/
#+BEGIN_QUOTE
If a node joins the cluster either for the first time or after a
period of prolonged downtime, it may need to obtain a complete
snapshot of the database from some other node. This operation is
called State Snapshot Transfer or SST, and is often reasonably quick
in a LAN environment.

In a geo-distributed cluster, however, the dataset may need to travel
over a slow WAN link. A transfer that takes seconds over a 10Gb
network can take hours over a cable modem.

SST does not happen during the normal operation of the cluster, but
may be needed during an outage situation which is already a stressful
time for the DevOps. During SST, the joining node is not available and
the donating node may be in a read-only state or have degraded
performance.
#+END_QUOTE

Note: CockroachDB may shine during commissioning over WAN. It could be cool
to add a test on that particular topic (ie, measuring the downtime
when commissioning a new node -- it should be 0 on CockroachDB).

* Appendix
** Detailed experiments results
Listing [[lst:xps_oss_light]] computes the mean completion time (in
second) of Rally scenarios in a light mode and plots the results in
figure [[fig:xps_oss_light]]. In the following figure, columns presents
results of a specific scenario: the first column presents results for
Authenticate User and Validate Token, the second for Create Add and
List User Role. Rows present results with a specific RDBMS: first row
presents results for MariaDB, second for Galera and third for
CockroachDB. The figure presents results with stacked bar charts. A
bar presents the result for a specific number of OpenStack instances
(/i.e./, ~3~, ~9~ and ~45~) and stacks completion times of each
Keystone operations.

*** Number of OpenStack instances impact under light load
#+NAME: lst:xps_oss_light
#+BEGIN_SRC python :results file :noweb yes :exports both
oss_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/oss-impact-light',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter light load
          .filter(compose(not_, is_high))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
           .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the mean, std and success of the results
          <<lst:median_ctime>>))
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load
#+CAPTION: -- Mean Time for Every Operations (Lower is Better).
#+NAME: fig:xps_oss_light
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_light
[[file:imgs/oss-impact-light.png]]

#+NAME: lst:xps_oss_light_cdf
#+BEGIN_SRC python :results file :noweb yes :exports both
oss_plot("%s Cumulative Percent",
         series_linear_plot,
         'imgs/oss-impact-light-cdf',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter light load
          .filter(compose(not_, is_high))
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the CDF of the resuls
          <<lst:cdf>>),
         legend='all')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under Light Load
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_oss_light
#+ATTR_ORG: :width 50
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_oss_light_cdf
[[file:imgs/oss-impact-light-cdf.png]]

*** Number of OpenStack instances impact under high load
#+NAME: lst:xps_oss_high
#+BEGIN_SRC python :results file :noweb yes :exports both
oss_plot("%s Completion Time (s)",
         series_stackedbar_plot,
         'imgs/oss-impact-high',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter high load
          .filter(is_high)
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the mean, std and success of the results
          <<lst:median_ctime>>))
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load
#+CAPTION: -- Median Time for Every Operations (Lower is Better).
#+NAME: fig:xps_oss_high
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_high
[[file:imgs/oss-impact-high.png]]

#+NAME: lst:xps_oss_high_cdf
#+BEGIN_SRC python :results file :noweb yes :exports both
oss_plot("%s Cumulative Percent",
         series_linear_plot,
         'imgs/oss-impact-high-cdf',
         (# -- Experiments selection
          <<lst:xps_oss>>
          # Filter high load
          .filter(is_high)
          # Group results by scenario's name, RDBMS technology and
          # number of OpenStack instances.
          .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.oss))
          # Compute the CDF of the resuls
          <<lst:cdf>>
         ), legend='all')
#+END_SRC

#+CAPTION: Impact of the Number of OpenStack Instances on the Completion Time under High Load
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_oss_high_cdf
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_oss_high_cdf
[[file:imgs/oss-impact-high-cdf.png]]

*** Delay impact under light load
#+NAME: lst:xps_delay_light
#+BEGIN_SRC python :results file :noweb yes :exports both
delay_plot("%s Completion Time (s)",
           series_stackedbar_plot,
           'imgs/delay-impact-light',
           (# -- Experiments selection
            <<lst:xps_delay>>
            # Filter light load
            .filter(compose(not_, is_high))
            # Group results by scenario's name, RDBMS technology and
            # delay
            .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
            # Compute the mean, std and success of the results
            <<lst:median_ctime>>
         ))
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under Light Load
#+CAPTION: -- Median Time for Every Operations (Lower is Better).
#+NAME: fig:xps_delay_light
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_light
[[file:imgs/delay-impact-light.png]]

#+NAME: lst:xps_delay_light_cdf
#+BEGIN_SRC python :results file :noweb yes :exports both
delay_plot("%s Cumulative Percent",
           series_linear_plot,
           'imgs/delay-impact-light-cdf',
           (# -- Experiments selection
            <<lst:xps_delay>>
            # Filter light load
            .filter(compose(not_, is_high))
            # Group results by scenario's name, RDBMS technology and
            # delay
            .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
            # Compute the CDF
            <<lst:cdf>>
         ), legend='all')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under Light Load
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_delay_light_cdf
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_light_cdf
[[file:imgs/delay-impact-light-cdf.png]]

*** Delay impact under high load
#+NAME: lst:xps_delay_high
#+BEGIN_SRC python :results file :noweb yes :exports both
delay_plot("%s Completion Time (s)",
           series_stackedbar_plot,
           'imgs/delay-impact-high',
           (# -- Experiments selection
            <<lst:xps_delay>>
            # Filter high load
            .filter(is_high)
            # Group results by scenario's name, RDBMS technology and
            # delay
            .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
            # Compute the mean, std and success of the results
            <<lst:median_ctime>>
         ))
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under High Load
#+CAPTION: -- Median Time for Every Operations (Lower is Better).
#+NAME: fig:xps_delay_high
#+ATTR_HTML: :class zoom-on-click
#+RESULTS: lst:xps_delay_high
[[file:imgs/delay-impact-high.png]]

#+NAME: lst:xps_delay_high_cdf
#+BEGIN_SRC python :results file :noweb yes :exports both
delay_plot("%s Cumulative Percent",
           series_linear_plot,
           'imgs/delay-impact-high-cdf',
           (# -- Experiments selection
            <<lst:xps_delay>>
            # Filter high load
            .filter(is_high)
            # Group results by scenario's name, RDBMS technology and
            # delay
            .group_by(lambda xp: (xp.scenario, xp.rdbms, xp.delay))
            # Compute the CDF
            <<lst:cdf>>
         ), legend='all')
#+END_SRC

#+CAPTION: Impact of the Network Delay on the Completion Time under High Load
#+CAPTION: -- Cumulative Distribution.
#+NAME: fig:xps_delay_high_cdf
#+ATTR_HTML: :class zoom-on-click
#+ATTR_ORG: :width 50
#+RESULTS: lst:xps_delay_high_cdf
[[file:imgs/delay-impact-high-cdf.png]]

*** Take into account the client locality
** Detailed Rally scenarios
*** keystone/authenticate-user-and-validate-token
Description: authenticate and validate a keystone token.

Definition Code:
[[https://github.com/openstack/rally-openstack/blob/6158c1139c0a4d88cab74481c5cbfc8be398f481/samples/tasks/scenarios/keystone/authenticate-user-and-validate-token.yaml][samples/tasks/scenarios/keystone/authenticate-user-and-validate-token]]

Source Code:
[[https://github.com/openstack/rally-openstack/blob/b1ae405b7fab355f3062cdb56a5b187fc6f2907f/rally_openstack/scenarios/keystone/basic.py#L111-L120][rally_openstack.scenarios.keystone.basic.AuthenticateUserAndValidateToken]]

List of keystone functionalities:
1. keystone_v3.fetch_token
2. keystone_v3.validate_token

%Reads/%Writes: 96.46/3.54

Number of runs: 20

*** keystone/create-add-and-list-user-roles
Description: create user role, add it and list user roles for given
user.

Definition Code:
[[https://github.com/openstack/rally-openstack/blob/6158c1139c0a4d88cab74481c5cbfc8be398f481/samples/tasks/scenarios/keystone/create-add-and-list-user-roles.yaml][samples/tasks/scenarios/keystone/create-add-and-list-user-roles]]

Source Code:
[[https://github.com/openstack/rally-openstack/blob/b1ae405b7fab355f3062cdb56a5b187fc6f2907f/rally_openstack/scenarios/keystone/basic.py#L214-L228][rally_openstack.scenarios.keystone.basic.CreateAddAndListUserRoles]]

List of keystone functionalities:
1. keystone_v3.create_role
2. keystone_v3.add_role
3. keystone_v3.list_roles

%Reads/%Writes: 96.22/3.78

Number of runs: 100

*** keystone/create-and-list-tenants
Description: create a keystone tenant with random name and list all
tenants.

Definition Code:
[[https://github.com/openstack/rally-openstack/blob/6158c1139c0a4d88cab74481c5cbfc8be398f481/samples/tasks/scenarios/keystone/create-and-list-tenants.yaml][samples/tasks/scenarios/keystone/create-and-list-tenants]]

Source Code:
[[https://github.com/openstack/rally-openstack/blob/b1ae405b7fab355f3062cdb56a5b187fc6f2907f/rally_openstack/scenarios/keystone/basic.py#L166-L181][rally_openstack.scenarios.keystone.basic.CreateAndListTenants]]

List of keystone functionalities:
1. keystone_v3.create_project
2. keystone_v3.list_projects

%Reads/%Writes: 92.12/7.88

Number of runs: 10

*** keystone/get-entities
Description: get instance of a tenant, user, role and service by id's.
An ephemeral tenant, user, and role are each created. By default,
fetches the 'keystone' service.

List of keystone functionalities:
1. keystone_v3.create_project
2. keystone_v3.create_user
3. keystone_v3.create_role
   1) keystone_v3.list_roles
   2) keystone_v3.add_role
4. keystone_v3.get_project
5. keystone_v3.get_user
6. keystone_v3.get_role
7. keystone_v3.list_services
8. keystone_v3.get_services

%Reads/%Writes: 91.9/8.1

Definition Code:
[[https://github.com/openstack/rally-openstack/blob/6158c1139c0a4d88cab74481c5cbfc8be398f481/samples/tasks/scenarios/keystone/get-entities.yaml][samples/tasks/scenarios/keystone/get-entities]]

Source Code:
[[https://github.com/openstack/rally-openstack/blob/b1ae405b7fab355f3062cdb56a5b187fc6f2907f/rally_openstack/scenarios/keystone/basic.py#L231-L261][rally_openstack.scenarios.keystone.basic.GetEntities]]

Number of runs: 100

*** keystone/create-user-update-password
Description: create user and update password for that user.

List of keystone functionalities:
1. keystone_v3.create_user
2. keystone_v3.update_user

%Reads/%Writes: 89.79/10.21

Definition Code:
[[https://github.com/openstack/rally-openstack/blob/6158c1139c0a4d88cab74481c5cbfc8be398f481/samples/tasks/scenarios/keystone/create-user-update-password.yaml][samples/tasks/scenarios/keystone/create-user-update-password]]

Source Code:
[[https://github.com/openstack/rally-openstack/blob/b1ae405b7fab355f3062cdb56a5b187fc6f2907f/rally_openstack/scenarios/keystone/basic.py#L306-L320][rally_openstack.scenarios.keystone.basic.CreateUserUpdatePassword]]

Number of runs: 100

*** keystone/create-user-set-enabled-and-delete
Description: create a keystone user, enable or disable it, and delete
it.

List of keystone functionalities:
1. keystone_v3.create_user
2. keystone_v3.update_user
3. keystone_v3.delete_user

%Reads/%Writes: 91.07/8.93

Definition Code:
[[https://github.com/openstack/rally-openstack/blob/6158c1139c0a4d88cab74481c5cbfc8be398f481/samples/tasks/scenarios/keystone/create-user-set-enabled-and-delete.yaml][samples/tasks/scenarios/keystone/create-user-set-enabled-and-delete]]

Source Code:
[[https://github.com/openstack/rally-openstack/blob/b1ae405b7fab355f3062cdb56a5b187fc6f2907f/rally_openstack/scenarios/keystone/basic.py#L75-L91][rally_openstack.scenarios.keystone.basic.CreateUserSetEnabledAndDelete]]

Number of runs: 100

*** keystone/create-and-list-users
Description: create a keystone user with random name and list all
users.

List of keystone functionalities:
1. keystone_v3.create_user
2. keystone_v3.list_users

%Reads/%Writes: 92.05/7.95

Definition Code:
[[https://github.com/openstack/rally-openstack/blob/6158c1139c0a4d88cab74481c5cbfc8be398f481/samples/tasks/scenarios/keystone/create-add-and-list-user-roles.yaml][samples/tasks/scenarios/keystone/create-and-list-users]]

Source Code:
[[https://github.com/openstack/rally-openstack/blob/b1ae405b7fab355f3062cdb56a5b187fc6f2907f/rally_openstack/scenarios/keystone/basic.py#L145-L163][rally_openstack.scenarios.keystone.basic.CreateAndListUsers]].

Number of runs: 100

* Footer                                                           :noexport:
#+BEGIN_EXPORT html
<script type="text/javascript">
$(document).ready(function () {

  // Strip tables
  $('.table-striped').DataTable({
    searching: false,
    stateSave: false,
    ordering: false,
    autowidth: false
  });

  $('.dataTables_length').hide();

  // Zoom images on click
  $('.zoom-on-click').wrap(function() {
    var img_url = $(this).attr('src');
    var img_caption = $(this).next('figcaption').text();
    var img_html = $(this).html();

    return "<a href='" + img_url + "' data-caption='" + img_caption + "' data-fancybox='gallery'>" +  img_html + "</a>";
  });
});
</script>
#+END_EXPORT

* Footnotes
[fn:global-id] TODO(Comment on global identifier): general way to
implement this is vector clock + causal broadcast (i.e., costly
operation). Actually, galera do not tell how it implement this but say
that it uses a clock that may differ of 1 second from one peer to
another. This means that two concurrent transactions, on two different
peers, done during the same second may end with the same id.
Henceforth, Galera do not ensure first order commit and inconsistency
may arises.

[fn:os-deplyment-alternatives] Here we present two deployment
alternatives. But there are several others such as multiple regions,
CellV2 and federation deployment.
